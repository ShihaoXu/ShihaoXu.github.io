<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="" />
    <meta name="author" content="徐世豪" />
    <meta name="generator" content="Pelican (VoidyBootstrap theme)" />

    <title>Reading notes of Hands-On Machine Learning with Scikit-Learn and TensorFlow - 汪酱的blog</title>

   
        <link rel="stylesheet"
              href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"
              integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u"
              crossorigin="anonymous" />
      <link rel="stylesheet"
            href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"
            integrity="sha384-wvfXpqpZZVQGK6TAh5PVlGOfQNHSoD2xbE+QkPxCAFlNEevoEH3Sl0sibVcOQVnN"
            crossorigin="anonymous">


      <link rel="stylesheet" href="/theme/css/pygment.css" />
      <link rel="stylesheet" href="/theme/css/voidybootstrap.css" />

    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js" integrity="sha384-FFgGfda92tXC8nCNOxrCQ3R8x1TNkMFqDZVQdDaaJiiVbjkPBXIJBx0o7ETjy8Bh" crossorigin="anonymous"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js" integrity="sha384-ZoaMbDF+4LeFxg6WdScQ9nnR1QC2MIRxA1O9KWEXQwns1G8UNyIEZIQidzb0T1fo" crossorigin="anonymous"></script>
    <![endif]-->

    <link rel="shortcut icon" href="/favicon.ico" />
  </head>

  <body>
   
    <nav class="navbar navbar-default">
      <div class="container">
	   <div class="navbar-header">
		<button type="button" class="navbar-toggle" 
				data-toggle="collapse" data-target="#main-navbar-collapse">
		  <span class="sr-only">Toggle navigation</span>
		  <span class="icon-bar"></span>
		  <span class="icon-bar"></span>
		  <span class="icon-bar"></span>
		</button>
		<a class="navbar-brand" href="/" rel="home">
          <i class="fa fa-home fa-fw fa-lg"> </i> </a>
       </div>

      <div class="collapse navbar-collapse" id="main-navbar-collapse">
        <ul class="nav navbar-nav">
            <li class="">
              <a href="/archives.html">Archives</a>
            </li>
          <li class="divider"></li>
        </ul> <!-- /nav -->
      </div> <!-- /navbar-collapse -->
	  </div> <!-- /container -->
    </nav> <!-- /navbar -->

	<div class="jumbotron" id="overview">
	  <div class="container">
		<h1><a href="/">汪酱的blog</a></h1>
		<p class="lead">I'm just thinking a lot about the site subtitle</p>
	  </div>
	</div>

    <div class="container" id="main-container">
      <div class="row">
        <div class="col-md-9" id="content">
<article itemscope="itemscope" itemtype="http://schema.org/BlogPosting">
  <header class="article-header">
<abbr class="article-header-date">
  Wed 21 February 2018
</abbr> <h1>
  <a href="/reading-notes-hands-on-machine-learning-with-scikit-learn-and-tensorflow.html" rel="bookmark"
     title="Permalink to Reading notes of Hands-On Machine Learning with Scikit-Learn and TensorFlow">
    Reading notes of <cite>Hands-On Machine Learning with Scikit-Learn and TensorFlow</cite>
  </a>
</h1><div class="article-header-info">
  <p>
      Posted by <a href="/author/shihao-xu.html">Shihao Xu</a>
    in 
    <a href="/category/reading-notes.html">
      Reading Notes</a>
    &nbsp;&nbsp;
  </p>
</div> <!-- /.article-header-info -->  </header>
  <div class="content-body" itemprop="text articleBody">
	<p>Resources:</p>
<ol class="arabic simple">
<li><cite>Hands-on Machine Learning with Scikit-Learn and TensorFlow</cite></li>
<li><a class="reference external" href="https://www.tensorflow.org/api_docs/python/">TensorFlow API</a> : TensorFlow documentation, tutorials, examples and important notes on concept/implementation.</li>
<li><a class="reference external" href="https://github.com/tensorflow">TensorFlow's Repository</a> : TensorFlow implementation, a number of different models implemented in TF, it also has some pretrained models.</li>
</ol>
<div class="section" id="chapter-1-the-machine-learning-landscape">
<h2>Chapter 1 - The Machine Learning Landscape</h2>
<p>Very common and useful ML products:</p>
<ul class="simple">
<li><strong>OCR</strong> (Optical Character Recognition)</li>
<li>Spam filter</li>
</ul>
<p><strong>What is ML?</strong></p>
<ul class="simple">
<li>The science (and art) of programming computers so they can <strong>learn from data</strong>.</li>
<li>[Arthur Samuel, 1959] The field of study that gives computers the ability to learn without being explicity programmed.</li>
<li>[Tom Mitchell, 1997] A computer program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.</li>
</ul>
<p><strong>training instance (samples), training set</strong></p>
<p><strong>Nomenclature</strong></p>
<ul class="simple">
<li>In statistics hypothesis testing,<ul>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Null_hypothesis">null hypothesis</a>: a general statement or default position that there is no relationship between two measured phenomena, or no association among groups.</li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Type_I_and_type_II_errors">type I error</a>: the rejection of a true null hypothesis (&quot;false positive&quot; finding, or falsely infer the existence of something that is not there)</li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Type_I_and_type_II_errors">type II error</a>: retaining a false null hypothesis ()&quot;false negative&quot; finding, or falsely infer the absence of something that is)</li>
</ul>
</li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Precision_and_recall">true positives, true negatives, false positives, and false negatives</a><ul>
<li>compare the results of the classifier under test with trusted external judgments.</li>
<li>The terms <em>positive</em> and <em>negative</em> refer to the classifier's prediction (sometimes known as the <strong>expectation</strong>)</li>
<li>the terms <em>true</em> and <em>false</em> refer to whether that prediction corresponds to the external judgment (sometimes known as the <strong>observation</strong>).</li>
</ul>
</li>
<li><a class="reference external" href="https://en.wikipedia.org/wiki/Precision_and_recall">Performance Measurement</a> [In the context of Pattern Recognition, information retrieval, binary classification]<ul>
<li><strong>Precision</strong> (means &quot;how useful the results are&quot;, measure of exactness, or <em>quality</em>)</li>
<li><strong>Accuracy</strong> (also known as <strong>Sensitivity</strong>, means &quot;how complete the results are&quot;, measure of completeness, or <em>quantity</em>)</li>
</ul>
</li>
</ul>
<p><strong>ML is great for?</strong></p>
<ul class="simple">
<li>Problems for which existing solutions require a lot of hand-tuning or long lists of rules: one ML algorithm can often simplify code and perform better</li>
<li>Complex problems for which there is no good solution at all using a traditional approach: the best ML techniques can find a solution.
(For problems that either are too complex for traditional approaches or have no known algorithm)</li>
<li>Fluctuating environments: a ML system can adapt to new data</li>
<li>Getting insights about complex problems and large amounts of data<ul>
<li>ML can help humans hearn. Some ML algorithms can be inspected to see what they have learned. Sometimes this will reveal unsuspected correlations or new trends, and thereby lead to a better
understanding of the problem.</li>
<li>Applying ML techniques to dig into large amounts of data can help discover patterns that were not immediately apparent. This is called <strong>data mining</strong>.</li>
</ul>
</li>
</ul>
<div class="section" id="types-of-machine-learning-systems">
<h3>Types of Machine Learning Systems</h3>
<ul class="simple">
<li>Trained with human supervision?<ul>
<li><strong>Supervised Learning</strong>: training data includes the desired solutions - <strong>labels</strong>.</li>
<li><strong>Unsupervised Learning</strong>: the system tries to learn without a teacher</li>
<li><strong>Semisupervised Learning</strong>: deals with partially labeled training data, usually lots of unlabeld data and little bit of labeled data. Example: <strong>photo hosting service</strong> <a class="citation-reference" href="#phs1" id="id1">[phs1]</a> .</li>
<li><strong>Reinforcement Learning (RL)</strong>: In the context of RL, the learning system is called an <strong>agent</strong>. It can observe the environment, select and perform actions, and get <em>rewards</em> in return (or <em>penalties</em> in the form of
negative rewards). It must then learn by itself what is <strong>the best strategy, called a policy</strong>, to get the most reward over time.</li>
</ul>
</li>
<li>Can learn incrementally from a stream of incoming data?<ul>
<li>online learning</li>
<li>batch learning</li>
</ul>
</li>
<li>How to use the new training samples?<ul>
<li>instance-based learning</li>
<li>model-based learning</li>
</ul>
</li>
</ul>
<div class="section" id="supervised-unsupervised-learning">
<h4>Supervised/Unsupervised Learning</h4>
<div class="section" id="supervised-learning">
<h5>Supervised Learning</h5>
<p>Two typical supervised learning tasks:</p>
<ul class="simple">
<li>The algorithm/task class - <strong>classcification</strong>: learns to predict <em>the target class</em> of a new instance based on the <em>features</em></li>
<li>The algorithm/task class - <strong>regression</strong>: learns to predict <em>the target numeric value</em> of a new instance based on <em>features</em> (or <em>predictors</em>). The name <em>regression</em> originates from <em>regression to the mean</em></li>
<li>Some regression algorithms can be used for classification and vice versa. For example, logistic regression are off used for classfication, but also can output a value representing
the probability of belonging to a given class.</li>
<li>In ML, an <strong>attribute</strong> is a data type, while a <strong>feature</strong> has several meanings depending on the context, but generally means <em>an attribute plus its value</em>. Many use these words interchangeably.</li>
</ul>
<p>Some most important supervised learning algorithms:</p>
<ul class="simple">
<li><strong>k-Nearest Neighbors</strong></li>
<li><strong>Linear Regression</strong></li>
<li><strong>Logistic Regression</strong></li>
<li><strong>Support Vector Machines (SVMs)</strong></li>
<li><strong>Decision Trees and Random Forests</strong></li>
<li><strong>Neural Networks</strong>. Some NN architectures can be unsupervised (autoencoders, restricted Boltzmann machines), and semisupervised (Deep Belief Networks, unsupervised pretraining).</li>
</ul>
</div>
<div class="section" id="unsupervised-learning">
<h5>Unsupervised Learning</h5>
<ul>
<li><p class="first"><strong>Clustering</strong>: Group the samples based on rules/measures.</p>
<ul class="simple">
<li><em>k-Means</em></li>
<li><em>Hierarchical Cluster Analysis (HCA)</em>: can also subdivide each group into smaller groups</li>
<li><em>Expectation Maximization</em></li>
</ul>
</li>
<li><p class="first"><strong>Visualization and dimensionality reduction</strong>: You feed them a lot of complex and unlabeled data, they output a 2D or 3D representation of your data, preserving as much structure as they can,
so you can understand how to data is organized and perhaps identify unsuspected patterns.</p>
<p>A related task is <em>dimensionality reduction</em>, in which the goal is to simplify the data without losing too much information. One way to do this is to merge several correlated features into one. This is called <strong>feature extraction</strong>.
Apply Dimensionality Reduction before you feed it to another ML algorithm so that the system run faster and the data will take up less disk and memory space and in some cases may also perform better.</p>
<p>Another important unsupervised task is <em>anomaly detection</em>. For example: automatically removing outliers from a dataset before feeding it to another learning algorithm. <em>The system is trained with normal instances only</em>.</p>
<p>Finally, another common unsupervised task is <em>association rule learning</em>: dig into large amounts of data and discover interesting relations between attributes.</p>
<ul class="simple">
<li><em>Principal Component Analysis (PCA)</em></li>
<li><em>Kernel PCA</em></li>
<li><em>Locally-Linear Embedding (LLE)</em></li>
<li><em>t-distributed Stochastic Neighbor Embedding (t-SNE)</em></li>
</ul>
</li>
<li><p class="first"><strong>Association rule learning</strong>: <em>Apriori</em>, <em>Eclat</em></p>
</li>
</ul>
</div>
<div class="section" id="semi-supervised-learning">
<h5>Semi-Supervised Learning</h5>
</div>
<div class="section" id="reinforcement-learning">
<h5>Reinforcement Learning</h5>
<p>A <em>policy</em> defines what action the agent should choose when it is <em>in a given situation</em>.</p>
<ol class="arabic simple">
<li>Observe (the environment or situation)</li>
<li>Select action using policy</li>
<li>Action</li>
<li>Get reward or penalty</li>
<li>Update policy (learning step)</li>
<li>Iterate until an optimal policy is found</li>
</ol>
</div>
</div>
<div class="section" id="batch-and-online-learning">
<h4>Batch and Online Learning</h4>
<p>Criterion: Whether or not the system can learn incrementally from a stream of incoming data.</p>
<div class="section" id="batch-learning">
<h5>Batch Learning</h5>
<ul class="simple">
<li>The system must be trained using all the available data. <em>takes a lot of time and computing resources, typically done offline</em></li>
<li>First the system is trained, then it is launched into production and run without learning anymore.</li>
</ul>
<p>If you want a batch system to know about new data, you need to train a new version of the system from scratch on the full dataset,
then stop the old system and replace with the new one.</p>
<p>If your system needs to adapt to rapidly changing data (e.g., predict stock prices), then you need a more reactive solution)</p>
<p>If the amount of data is huge, it may even be impossible to use a batch learning algorithm.</p>
</div>
<div class="section" id="online-learning">
<h5>Online Learning</h5>
<p>The system is trained incrementally by feeding it data instances sequentially, either individually or by small groups called <strong>mini-batches</strong>.
Each learning step is fast and cheap, so the sys can learn about new data on the fly, as it arrives.</p>
<p>Online learning is great for systems that receive data as a continuous flow and need to adapt to changes rapidly or autonomously.</p>
<p>Once a online-learning system has learned about new data instances, it doesn't need them anymore, so you can discard them unless you want to be
able to rollback to a previous state.</p>
<p><strong>Out-of-core Learning</strong> <a class="citation-reference" href="#ol1" id="id2">[ol1]</a> can be achieved often by online learning algorithms.</p>
<p>The training process of a online-learning system is usually done offline, better called <strong>incremental learning</strong> instead.</p>
<p><strong>The learning rate (in the context of online-learning system)</strong> how fast they should adapt to changing data.</p>
<ul class="simple">
<li>high: rapid adaptation to changing data, forget the old samples fast.</li>
<li>low: slow adaptation, show inertia, less sensitive to noise in the new data.</li>
</ul>
<p>A new challange with online-learning: if bad data is fed to the system, the system's performance will gradually decline.</p>
<ul class="simple">
<li>To reduce this risk, you need to monitor your system closely and promptly switch learning off (and possibly revert to a previously working state).
If you detect a drop in performance. You may also want to monitor the input data and react to abnormal data (e.g., using an anomaly detection algorithm).</li>
</ul>
</div>
</div>
<div class="section" id="instance-based-vs-model-based-learning">
<h4>Instance-Based vs. Model-Based Learning</h4>
<p><strong>Criterion: How the ML system generalize</strong>: given a number of training examples, the system needs to be able to generalize to examples it has never seen before.
The true goal is to perform well on new distances.</p>
<p>Two main approaches to generalization: Instance-Based Learning and Model-Based Learning</p>
<div class="section" id="instance-based-learning">
<h5>Instance-Based Learning</h5>
<p>Learn by heart, then generalizes to new cases using a <strong>similarity measure</strong> (measure of similarity between two instances).</p>
<p>Example (k-NN here):</p>
<ol class="arabic simple">
<li><tt class="docutils literal">model = sklearn.neighbors.KNeighborsRegressor(n_neighbors=3)</tt></li>
<li><tt class="docutils literal">model.fit(X, y)</tt></li>
<li><tt class="docutils literal">model.predict(X_new)</tt></li>
</ol>
</div>
<div class="section" id="model-based-learning">
<h5>Model-Based Learning</h5>
<p>Build a model of these examples, then use that model to make predictions.</p>
<p>Steps:</p>
<ol class="arabic simple">
<li><strong>Model selection</strong> (e.g., linear model with one attribute) with <strong>model parameters</strong>.</li>
<li>Specify a <strong>performance measure</strong><ul>
<li><strong>utility/fitness function</strong>: measures how good your model is</li>
<li><strong>cost function</strong>: measures how bad your model is</li>
</ul>
</li>
<li>Use (say) cost minimization algorithm<ul>
<li>feed it your training examples</li>
<li>it finds the parameters that make the model fit best to your data (<strong>train the model</strong>)</li>
</ul>
</li>
<li>Run the model to make predictions</li>
<li>At the end of the training:<ul>
<li>If all went well, great!</li>
<li>If not, you may need to<ul>
<li>use more attributes</li>
<li>get more or better quality training data,</li>
<li>perhaps select a more powerful model</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>Examples:</p>
<ol class="arabic simple">
<li><tt class="docutils literal">model = <span class="pre">sklearn.linear_model.LinearRegression(...)</span></tt></li>
<li><tt class="docutils literal">model.fit(X, y)</tt></li>
<li><tt class="docutils literal">model.predict(X_new)</tt></li>
</ol>
<p>Summary for Model-Based Learning:</p>
<ul class="simple">
<li>You study the data</li>
<li>You select the model</li>
<li>You train it on the tarining data (i.e., the learning algorithm searched for the model parameter values that minimize a cost function)</li>
<li><strong>Inference</strong>: aplly the model to make prediction on new cases, hoping that this model will generalize well.</li>
</ul>
</div>
</div>
</div>
<div class="section" id="main-challenges-of-machine-learning">
<h3>Main Challenges of Machine Learning</h3>
<p>Two things can go wrong: bad algorithm and/or bad data.</p>
<ul class="simple">
<li><em>insufficient quantity of training data</em><ul>
<li>In a famous paper <a class="reference external" href="goo.gl/R5enIE">goo.gl/R5enIE</a> published in 2001, two reserchers showed that very different ML algorithms, including fairly simple ones, performed almost identically well on a complex problem of natural language
disambiguition once they were given enough data. The results suggests that we may want to reconsider the trade-off between spending time and money on algorithm development vs. spending it on corpus developement.</li>
<li><a class="reference external" href="goo.gl/q6LaZ8">goo.gl/q6LaZ8</a></li>
</ul>
</li>
<li><em>non-representative training data</em><ul>
<li>It is crucial that your training data be representative of the new cases you want to generalize to<ul>
<li>number of samples too small: <strong>sampling noise</strong>, nonrepresentative data as a result of chance</li>
<li>number of samples too large: <strong>sampling bias</strong>, very large samples can be nonrepresentative if the sampling method is flawed. A special type of sampling bias: <strong>nonresponse bias</strong>.</li>
</ul>
</li>
</ul>
</li>
<li><em>poor-quality data</em> (you need to clean up your training data, most data scientist spend a significant part of time doing just this)<ul>
<li><strong>outliers</strong>: simply discard them or try to fix the errors manually</li>
<li><strong>some instances miss a few features</strong>: you must decide whether you want to ignore this attribute altogether, ignore these instances, fill in the missing values (e.g., with median) or
train one model with the feature and one without it.</li>
</ul>
</li>
<li><em>irrelevant features</em><ul>
<li><strong>feature engineering</strong> <a class="citation-reference" href="#fe1" id="id3">[fe1]</a></li>
</ul>
</li>
<li><em>overfitting the training data (overgeneralizing)</em>: the model performs well on the training data, but doesn't generalize well<ul>
<li>complex models such as DNNs can detect subtle patterns in the data but if the training set is noisy, or if it is too small (which introduces <em>sampling noise</em>), then the model is likely to detect patterns in the noise itself.</li>
<li>overfitting happens when the model is too complex relative to the amount and moisiness of the training data. The possible solutions are:<ul>
<li>simplify the model by selecting one with fewer parameters, by reducing the number of attributs in the training data or by constraining the model (<strong>regularization</strong>)[reg1]_. The amount of regularization to apply during learning
can be controlled by a <strong>hyperparameter</strong> (a parameter of a learning algorithm, not of the model. Distinguish with the model parameter). It must be set prior to training and remains constant during training.</li>
<li>gather more data</li>
<li>reduce the noise in the training data (fix data errors, remove outliers)</li>
</ul>
</li>
</ul>
</li>
<li><em>underfitting the training data</em>: your model is too simple to learn the underlying structure of the data. Options to fix it:<ul>
<li>select a more powerful model, with more parameters</li>
<li>feeding better features to the learning algorithm (<em>feature engineering</em>)</li>
<li>reducing the constrains on the model</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="testing-and-validating">
<h3>Testing and Validating</h3>
<p>The only way to know how well a model will generalize to new cases is to actually try it out on new cases.</p>
<p>An option: split your data into two sets: the training set and the test set. You train your model on the training set and test it using the test set.</p>
<dl class="docutils">
<dt><strong>Generalization Error/Out-of-sample Error)</strong></dt>
<dd>The error rate on new cases. This value tells you how well your model will perform on instances it has never seen before.</dd>
<dt><strong>The Validation Set</strong></dt>
<dd>In practice, in addition to the test set, we use a second <strong>holdout set</strong> - the validation set - to prevent you from adapting the model and hyperparameters to the test set.
You train multiple models with various hyperparameters using the training set, you select the model and hyperparameters that perform best on the validation set. If you're happy you run a single final test against the test set
to <strong>get and estimate of the generalization error</strong>.</dd>
<dt><strong>Cross-Validation</strong> TODO:</dt>
<dd>A technique to avoid &quot;wasting&quot; too much training data in validation sets.</dd>
<dt><strong>No Free Lunch Theorem</strong></dt>
<dd>A model is a simplifeid version of the observations. The simplifications are meant to discard the superfluous details that are unlikely to generalize to new instances. However, to decide what data to discard and what data to keep, you must make <strong>assumptions</strong>.
In the paper <a class="reference external" href="goo.gl/dzp946">goo.gl/dzp946</a>, David Wolpert demonstrated that if you make absolutely no assumption about the data, then there is no reason to prefer one model over any other. This is called the <strong>No Free Lunch (NFL) theorem</strong>. There is no model that is <em>a priori</em>
guaranteed to work better (hence the name of the theorem). The only way to know for sure which model is best is to evaluate them all. Since this is not possible, in practice you make some reasonable assumptions about the data and you evaluate only a few
reasonable models.</dd>
</dl>
<table class="docutils citation" frame="void" id="phs1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[phs1]</a></td><td><strong>Photo Hosting Service</strong>: Hosts semi-supervised learning algorithms that are combinations of unsupervised and supervised algorithms. For example, DBNs are based on unsupervised components called <em>RBM</em>s stacked on top of one another.
RBMs are trained sequentially in an unsupervised manner, and then the whole system is fine-tuned using supervised learning techniques.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ol1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id2">[ol1]</a></td><td><strong>Out-of-core Learning</strong>: Train systems on huge datasets that cannot fit in one machine's main memory.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="fe1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[fe1]</a></td><td><strong>Feature Engineering</strong>: Critical part of the success of a ML project is coming up with a good set of features to train on. It involves:</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="reg1" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[reg1]</td><td><p class="first"><strong>Regularization</strong>: Constrain a model to make it simpler and reduce the rick of overfitting. you can effectively constrain some parameters have some DoF (degree of freedom) in between (say) one and two DoF.</p>
<ul class="last simple">
<li><strong>feature selection</strong>: select the most useful features to train on among existing features.</li>
<li><strong>feature extraction</strong>: combining existing features to produce a more useful one (dimensionality reduction can help)</li>
<li>create new features by gathering new data.</li>
</ul>
</td></tr>
</tbody>
</table>
</div>
</div>
<hr class="docutils" />
<div class="section" id="chapter-2-end-to-end-machine-learning-projects">
<h2>Chapter 2 - End-to-End Machine Learning Projects</h2>
<dl class="docutils">
<dt><strong>End-to-End Learning</strong></dt>
<dd>The purpose of End-to-End Learning is that the system automatically learns internal representations (features) of the necessary processing steps.</dd>
</dl>
<p><em>Popular open data repositories</em></p>
<p>Dataset we use here: California Housing Prices dataset from StatLib repository (based on the 1990 California census). Modified a little (added a categorical attribute and removed a few features).</p>
<div class="section" id="look-at-the-big-picture">
<h3>Look at the big Picture</h3>
<p>First task: build a model of housing prices in California using the California census data.</p>
<p><strong>Block groups/districts</strong>: the smallest geographical unit for which the US Census Bereau publishes sample data.</p>
<p>Goal: the model should be able to predict the median housing price in any district, given all other metrics.</p>
<div class="section" id="frame-the-problem">
<h4>Frame the Problem</h4>
<p>Questions you should ask:</p>
<ol class="arabic simple">
<li>What exactyly is the objective?</li>
<li>What the current solution looks like?</li>
<li>How to frame the Problem? (ask yourself)</li>
</ol>
<dl class="docutils">
<dt><strong>signal</strong></dt>
<dd>A piece of information fed to a ML learning system. In reference to Shannon's information theory: you want a high signal/noise ratio.</dd>
<dt><strong>Data Pipeline</strong></dt>
<dd>A sequence of data processing components. Components are often run asynchronously. Each component pulls in a large amount of data, process it, spits out the result in another data store, ready for
the next component to use. Each component is fairly self-contained: the interface between components is (can be) simply the data store.</dd>
</dl>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="chapter-3-classification">
<h2>Chapter 3 - Classification</h2>
<div class="section" id="mnist-dataset">
<h3>MNIST Dataset</h3>
<p>MNIST</p>
<ul class="simple">
<li>The &quot;Hello World&quot; of Machine Learning</li>
<li>70000 small images of handwritten digits</li>
<li>Each image is labeled with the digit it represents</li>
<li>Dataset Structure:<ul>
<li>70000 images of handwritten digits</li>
<li>each image has 28x28 pixels</li>
<li>each pixel is of type <tt class="docutils literal">uint8</tt> and represents the intensity, ranging from 0 (white) to 255 (black)</li>
</ul>
</li>
<li><em>How to peek at one digit from the dataset</em>:
Grab an instance's feature vector, reshape it to a 28x28 array, and display it using Matplotlib's <tt class="docutils literal">imshow()</tt> function.</li>
</ul>
<p>Scikit-Learn provides many helper functions to download popular datasets.</p>
<ul>
<li><p class="first">Datasets loaded by Scikit-Learn generally have a similar <strong>dictionary structure</strong> including:</p>
<ul class="simple">
<li><tt class="docutils literal">DESCR</tt> key: describes the dataset</li>
<li><tt class="docutils literal">data</tt> key: an array with one row per instance and one column per feature</li>
<li><tt class="docutils literal">target</tt> key: an array with the labels</li>
</ul>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_mldata</span>
<span class="n">mnist</span> <span class="o">=</span> <span class="n">fetch_mldata</span><span class="p">(</span><span class="s1">&#39;MNIST original&#39;</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mnist</span><span class="p">[</span><span class="s2">&quot;data&quot;</span><span class="p">],</span> <span class="n">mnist</span><span class="p">[</span><span class="s2">&quot;target&quot;</span><span class="p">]</span>

<span class="kn">import</span> <span class="nn">matplotlib</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">some_digit</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="mi">36000</span><span class="p">]</span>
<span class="n">some_digit_image</span> <span class="o">=</span> <span class="n">some_digit</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">some_digit_image</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">matplotlib</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">binary</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s2">&quot;nearest&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
<span class="n">y</span><span class="p">[</span><span class="mi">36000</span><span class="p">]</span>
</pre></div>
</li>
</ul>
<p>Prepare the Dataset</p>
<ul class="simple">
<li>Create a test set and set it aside before inspecting the data closely.</li>
<li>Shuffle the dataset, which guarantee that all cross-validation folds will be similar.</li>
<li>Split the dataset into training and test set.</li>
</ul>
<div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:</span><span class="mi">60000</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="mi">60000</span><span class="p">:],</span> <span class="n">y</span><span class="p">[:</span><span class="mi">60000</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="mi">60000</span><span class="p">:]</span>
<span class="n">shuffle_index</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="mi">60000</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[</span><span class="n">shuffle_index</span><span class="p">],</span> <span class="n">y_train</span><span class="p">[</span><span class="n">shuffle_index</span><span class="p">]</span>
</pre></div>
</div>
<div class="section" id="training-a-binary-classifier">
<h3>Training a Binary Classifier</h3>
<p>Here, we only try to identify one digit 5: &quot;the 5-detector&quot;. It's an example of a <strong>binary classifier</strong>, capable of distinguishing between just two classes.</p>
<p>Pick a classifier and train it. We use a Stochastic Gradient Descent (SGD) classifier. SGD deals with training instances independently, one at a time,
so,</p>
<ul class="simple">
<li>SGD is capable of handling very large datasets efficiently</li>
<li>SGD is well suited for <strong>online learning</strong></li>
</ul>
<div class="highlight"><pre><span></span><span class="n">y_train_5</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_train</span> <span class="o">==</span> <span class="mi">5</span><span class="p">)</span> <span class="c1"># True for all 5s, False for all other digits</span>
<span class="n">y_test_5</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_test</span> <span class="o">==</span> <span class="mi">5</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>

<span class="n">sgd_clf</span> <span class="o">=</span> <span class="n">SGDClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">sgd_clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train_5</span><span class="p">)</span>
<span class="c1"># Use it to detect images of the number 5</span>
<span class="n">sgd_clf</span><span class="o">.</span><span class="n">predict</span><span class="p">([</span><span class="n">some_digit</span><span class="p">])</span>
</pre></div>
<p>The <code>SGDClassifier</code> relies on randomness during training (hence the name &quot;stochastic&quot;). If you want reproducible results, you should set the <code>random_state</code> parameter.</p>
</div>
<div class="section" id="performance-measures">
<h3>Performance Measures</h3>
<p>Evaluating a classifier is often significantly trickier than evaluating a regressor.</p>
<div class="section" id="measuring-accuracy-using-cross-validation">
<h4>Measuring Accuracy Using Cross-Validation</h4>
<p><em>A good way to evaluate a model is to use cross-validation.</em></p>
<p>TODO</p>
</div>
<div class="section" id="confusion-matrix">
<h4>Confusion Matrix</h4>
<p>A much better way to evaluate the performance of a classifier is to look at the <strong>confusion matrix</strong>. The general idea is to count the number of times instances of class A are classified as class B.
For example, to know the number of times the classifier confused images of 5s with 3s, you look in the 5th row and 3rd column of the confusion matrix.</p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="chapter-4-training-models">
<h2>Chapter 4 - Training Models</h2>
<div class="section" id="gradient-descent">
<h3>Gradient Descent</h3>
<p><strong>What is Gradient Descent?</strong></p>
<ul class="simple">
<li>It is a very generic optimization algorithm.</li>
<li>General idea: tweak parameters iteratively in order to minimize a cost function.</li>
<li>How it works?<ul>
<li>It measures the local gradient of the error function with regards to the parameter vector <span class="math">\(\theta\)</span>, it goes then in the direction of descending gradient.</li>
<li>Concretely:<ol class="arabic">
<li><strong>random initialization</strong> (fill <span class="math">\(\theta\)</span> randomly)</li>
<li>Improve it gradually. Each step attempts to decrease the cost function (e.g. MSE), until the algorithm <strong>converges</strong> to a minimum.</li>
</ol>
</li>
</ul>
</li>
</ul>
<p><strong>Details of Gradient Descent</strong></p>
<ul>
<li><p class="first">hyperparameter: <strong>learning rate</strong> <span class="math">\(\eta\)</span></p>
<ul class="simple">
<li>too small: takes too long to converge.</li>
<li>too high: possibly diverge, and/or fail to find a good solution.</li>
</ul>
</li>
<li><p class="first">Not all cost functions looks like nice regular bowls. Two main challenges with Gradient Descent:</p>
<ol class="arabic simple">
<li><strong>Local minimum</strong> vs. <strong>global minimum</strong></li>
<li><strong>plateau</strong>: takes a very long time to train. And if you stop too early, you will never reach the global (or even a local) minimum.</li>
</ol>
</li>
<li><p class="first">The MSE cost function for Linear Regression model happens to be a <strong>convex function</strong>, which implies that there are no local minima, just one global
minimum. It is also a continuous function with a slope that never changes abruptly (<strong>Lipschitz continuous</strong>)</p>
<ul class="simple">
<li>Consequence: Gradient Descent is guaranteed to approach arbitrarily close the global minimum (if you wait long enough and the learning rate is not too high).</li>
<li>In this case (convex function + lipschitz continuous) the cost function has a shape of a bowl. If the features are of very different scales, the bowl can be elongated (results in long training time).<ul>
<li>Solution: Before using Gradient Descent, ensure all features have a similar scale (e.g. Scikit-Learn's <tt class="docutils literal">StandardScaler</tt>).</li>
</ul>
</li>
</ul>
</li>
<li><p class="first"><em>Training a model</em> is equivalent to <em>searching for a comnibation of model parameters that minimizes a cost function</em> (over the training set).</p>
<p>It is a search in the model's <strong>parameter space</strong>. The more parameters a model has, the more dimensions this space has, the harder the search is.</p>
</li>
</ul>
<div class="section" id="batch-gradient-descent-batch-gd">
<h4>Batch Gradient Descent (Batch GD)</h4>
<p>Batch GD is an approach of gradient descent.</p>
<p>Batch GD computes the gradient of the cost function with regards to each <strong>model parameter</strong> <span class="math">\(\theta_j\)</span> - the <strong>partial derivative</strong>.</p>
<ul>
<li><p class="first">You can compute the partial derivative of the cost function w.r.t. parameter <span class="math">\(\theta_j\)</span>, noted <span class="math">\(\frac{\partial}{\partial \theta_j}\mathrm{MSE}(\theta)\)</span>
<span class="math">\(\frac{\partial}{\partial \theta_j}\mathrm{MSE}(\theta) = \frac{2}{m}\sum^m_{i=1}(\theta^T\cdot \vec{x}^{(i)}-y^{(i)})x_j^{(i)}\)</span></p>
</li>
<li><p class="first">Or you can choose the gradient vector, <span class="math">\(\nabla_\theta \mathrm{MSE}(\theta)\)</span>, which contains all the partial derivatives of the cost function (one for each model parameter).</p>
<div class="math">
\begin{equation*}
\nabla_\theta \mathrm{MSE}(\theta) = \begin{pmatrix} \frac{\partial}{\partial \theta_0}\mathrm{MSE}(\theta) \\
                                                     \frac{\partial}{\partial \theta_1}\mathrm{MSE}(\theta) \\
                                                     \vdots \\
                                                     \frac{\partial}{\partial \theta_n}\mathrm{MSE}(\theta)\end{pmatrix}
= \frac{2}{m}\mathbf{X}^T \cdot (\mathbf{X} \cdot \theta - \vec{y})
\end{equation*}
</div>
<ul class="simple">
<li>This formular involves calculations over the full training set <span class="math">\(\mathbf{X}\)</span>, at each gradient step.<ul>
<li>This is why the algorithm is called <strong>batch gradient descent</strong>. And why it is slow on very large training set.</li>
<li>Gradient descent <strong>scales well with the number of features</strong>. Training a Linear Regression on hundreds of thousands of features is much faster using Gradient Descent than using the Normal Equation.</li>
</ul>
</li>
<li><span class="math">\(\nabla_\theta \mathrm{MSE}(\theta)\)</span> points uphill. Subtract <span class="math">\(\nabla_\theta \mathrm{MSE}(\theta)\)</span>, multiplied by the learning rate <span class="math">\(\eta\)</span>, from <span class="math">\(\theta\)</span>: <span class="math">\(\theta^{\mathrm{next\ step}} = \theta - \eta \nabla_\theta \mathrm{MSE}(\theta)\)</span></li>
</ul>
</li>
</ul>
<p>Find a good learning rate: use <strong>grid search</strong> (while limiting the number of iterations so that grid search can eliminate models that take too long to converge).</p>
<ul class="simple">
<li><em>How to set the number of iterations?</em>
Set a very large number of iterations but interrupt the algorithm when the gradient vector becomes tiny - that is, when its norm becomes smaller than
a tiny number <span class="math">\(\epsilon\)</span> (the <strong>tolerance</strong>). It happens when gradient descent has (almost) reached the minimum.</li>
</ul>
<p>The <strong>Convergence Rate</strong></p>
<ul class="simple">
<li>Context:<ol class="arabic">
<li>convex cost function</li>
<li>slope doesn't change abruptly</li>
</ol>
</li>
<li>Batch GD with a fixed learning rate has a <strong>convergence rate</strong> of <span class="math">\(O(\frac{1}{\mathrm{iteration}})\)</span>. It means if you divide the tolerance <span class="math">\(\epsilon\)</span> by 10 (to have a more precise solution), then the algorithm will have to run about 10 times more iterations.</li>
</ul>
</div>
<div class="section" id="stochastic-gradient-descent-stochastic-gd">
<h4>Stochastic Gradient Descent (Stochastic GD)</h4>
<p>Problem of Batch GD: it uses the whole training set to compute the gradients at every step, which results in slow training process.</p>
<p>Stochastic GD picks a random instance in the training set at every step and computes the gradients based on that single instance.</p>
<ul class="simple">
<li>Stochastic GD can be implemented as an <strong>out-of-core</strong> algorithm.</li>
<li>Due to its stochastic nature, this algorithm is much less regular than Batch GD: the cost function will bounce up and down, decreasing only on average. Over time
it will end up very close to the minimum, but once it gets there, it will continue to bounce around, never settling down.
When the algorithm stops, the final parameters are good, but not optimal.</li>
</ul>
<p>Randomness of stochastic GD is good, for escaping from local optima, but also bad, because the algorithm can never settle at minimum.</p>
<ul class="simple">
<li>One solution: <strong>simulated anealing</strong> - gradually reduce the learning rate<ul>
<li>Start with large learning rate<ul>
<li>makes quick progress</li>
<li>escape local optima</li>
</ul>
</li>
<li>Get smaller and smaller: allowing the algorithm to settle at the global minimum</li>
<li><strong>learning schedule</strong>: the function that determines the learning rate at each iteration.</li>
</ul>
</li>
</ul>
<p>By convention we iterate by rounds of <span class="math">\(m\)</span> iterations, each round is called an <strong>epoch</strong>.</p>
<ul class="simple">
<li>Since instances are picked randomly, some instances may be picked several times per epoch while others may not be picked at all. If you want to be sure
that the algorithm goes through every instance at each epoch, another approach is to shuffle the training set, then go through it instance by instance, then shuffle it again,
and so on. <em>But it generally converges more slowly</em>.</li>
</ul>
<p>TODO: the code.</p>
</div>
<div class="section" id="mini-batch-gradient-descent-mbgd">
<h4>Mini-Batch Gradient Descent (MBGD)</h4>
<p>At each step, MBGD computes the gradients on small random sets of instances called <strong>mini-batches</strong>.</p>
<p>Main advantage of MBGD over stochastic GD: you can get a performance boost from hardware optimization of matrix operations, especially using GPUs.</p>
<p>The algorithm's progress in parameter space is less erratic than with stochastic GD, especially with fairly large mini-batches.</p>
<ul class="simple">
<li>MBGD will end up walking around a bit closer to the minimum than stochastic GD.</li>
<li>It is harder for it to escape from local optima.</li>
</ul>
<p>TODO: Comparison of Normal Equation, Batch GD, Stochastic GD, MBGD.</p>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="chapter-9-up-and-running-with-tensorflow">
<h2>Chapter 9 - Up and Running with TensorFlow</h2>
<p><strong>What is TensorFlow?</strong></p>
<ul class="simple">
<li>it is a powerful open source software library for numerical computation</li>
<li>particularly well suited and fine-tuned for large-scale ML.</li>
<li><strong>basic principle</strong>: You first define in Python a graph of computations to perform (<strong>computation graph</strong>), and then TensorFlow takes that graph and runs it efficiently using optimized C++ code.</li>
<li><strong>Scalablity/Parallelism</strong>: TF supports distributed computing. (train colossal NNs on humongous training sets by splitting the computations across hundreds of servers. It is possible to break up the graph into several chunks and run them in parallel across multiple CPUs or GPUs.)</li>
<li><strong>Flexibility</strong>: TF is not limited to neural networks or even Machine Learning.</li>
</ul>
<p><strong>TensorFlow's Highlights</strong></p>
<ul class="simple">
<li>multi-platform (even on mobile platforms)</li>
<li>provides a simple python API called <tt class="docutils literal">TF.Learn</tt> (<tt class="docutils literal">tensorflow.contrib.learn</tt>), compatible with Scikit-Learn</li>
<li>provides another simple API called <tt class="docutils literal"><span class="pre">TF-slim</span></tt> (<tt class="docutils literal">tensorflow.contrib.slim</tt>) to simplify building, training, and evaluating NNs.</li>
<li>several other high-level APIs have been build independently on top of TF, such as <tt class="docutils literal">Keras</tt> (<tt class="docutils literal">tensorflow.contrib.kera</tt>) or <tt class="docutils literal">Pretty Tensor</tt></li>
<li>its main Python API offers much more flexibility (at the cost of higher complexity) to create all sorts of computations, including any NN architectures.</li>
<li>It includes highly efficient C++ implementations of many ML operations. There is also a C++ API to define your own high-performance operations.</li>
<li>provides several <strong>advanced optimization nodes</strong> to search for the params that minimize a cost function, since TF automatically takes care of computing the gradients of the functions you define (which is called <strong>automatic differentiating</strong>, or <strong>autodiff</strong>).</li>
<li>it comes with a great visualization tool called <strong>TensorBoard</strong> that allows you to browse through the computation graph, view learning curves, and more.</li>
<li>Google launched a cloud service to run TF graphs.</li>
</ul>
<p><strong>The process of training a model (Construction Phase + Execution Phase)</strong></p>
<ol class="arabic simple">
<li>(Construction Phase) Create computation graph with a bottom-top approach</li>
<li>(Execution Phase) Open a TF session (place the op onto device run them, holds all the variable values). Within the session (<tt class="docutils literal">with</tt> sets <strong>the default session</strong>)<ol class="arabic">
<li>initialize variables</li>
<li>perform operations</li>
<li>(close the session, free up resources)</li>
</ol>
</li>
</ol>
<p><strong>Some Details</strong></p>
<ul class="simple">
<li><strong>interactive session</strong> vs. <strong>regular Session</strong> vs. <strong>the default session</strong></li>
<li><strong>graph managing</strong>, <strong>the default graph</strong>, reset the default graph, manage <strong>multiple independent graphs</strong></li>
<li>evaluate a node: TF automatically determines the set of nodes that it depends on and it evaluates those nodes first<ul>
<li>by default, TF won't reuse the result of the previous evaluation of the variables. All node values are dropped between graph runs, <strong>except variable values</strong>, which are maintained by the session across graph runs.</li>
<li>efficient single-graph-run evaluation <tt class="docutils literal">sess.run(y, z])</tt></li>
</ul>
</li>
<li><strong>TF operations</strong>: op</li>
<li><strong>tf.Variable</strong> and <strong>tf.constant</strong>: source ops, take no input. Variables usually contain the model and thus are to be trained.</li>
<li>input and output: multidimensional arrays (<strong>tensor</strong>), tensors have a type and shape.</li>
<li><strong>tf.placeholder</strong>, use the following methods to prepare the <tt class="docutils literal">feed_dict</tt> for the <tt class="docutils literal">tf.placeholder</tt>s<ul>
<li><tt class="docutils literal">NumPy</tt>'s <tt class="docutils literal">reshape()</tt> function takes <tt class="docutils literal"><span class="pre">-1</span></tt> for one of the dimensions, that dimension will be computed based on the array's length and the remaining dimensions.</li>
<li><tt class="docutils literal">np.c_[left_matrix, right_matrix]</tt></li>
</ul>
</li>
</ul>
<p><strong>Example 1: Linear Regression with TF (the normal equation)</strong></p>
<ul class="simple">
<li><strong>Linear Regressor</strong> with <strong>the normal equation</strong> <span class="math">\(\hat{\theta} = (\mathbf{X}^T \mathbf{X})^{-1} \mathbf{X}^T \mathbf{y})\)</span></li>
</ul>
<p><strong>Example 2: Batch Gradient Descent</strong></p>
<ol class="arabic simple">
<li>Normalize the input feature vectors before using Gradient Descent to speed up the training process (TF, Numpy, Scikit-Learn's <tt class="docutils literal">StandardScaler</tt>)<ul>
<li>&quot;Normalization&quot; here means: standardize features by removing the mean and scaling to unit variance.</li>
</ul>
</li>
<li>The Gradient Descent part<ul>
<li>Approache 1: manually compute the gradients<ul>
<li><tt class="docutils literal">random_uniform()</tt> similar to NumPy's <tt class="docutils literal">rand()</tt>: initialize the models with random numbers</li>
<li><tt class="docutils literal">tf.assign()</tt>: update the model parameters (in the <tt class="docutils literal">tf.Variable</tt>) after each iteration <span class="math">\(\theta^{\text{next step}}=\theta - \eta \nabla_{\theta}\mathrm{MSE}(\theta)\)</span></li>
<li><tt class="docutils literal">n_epochs</tt>: number of <strong>epochs</strong>. An epoch is a complete pass through a given dataset (ALL samples in the dataset. ) <a class="reference external" href="https://deeplearning4j.org/glossary">Epoch vs. Iteration</a></li>
</ul>
</li>
<li>Approache 2: use TF's <strong>autodiff</strong> feature<ul>
<li>like autodiff, <strong>symbolic differentiation</strong> can also achieve the goal, but not efficient</li>
<li>autodiff: automatically and efficiently computes the gradients for the user.</li>
<li><tt class="docutils literal">gradients = tf.gradients(mse, <span class="pre">[theta])[0]</span></tt></li>
</ul>
</li>
<li>Approache 3: Implicitly implement Gradient Descent using <strong>optimizers</strong><ul>
<li>Gradient Descent optimizer</li>
<li>Momentum Optimizer (converges faster than Gradient Descent)</li>
</ul>
</li>
</ul>
</li>
</ol>
<p><strong>Example 3: Mini-Batch Gradient Descent</strong></p>
<ul class="simple">
<li>feed data to the training algorithm</li>
<li><tt class="docutils literal">placeholder</tt> nodes (pass the training data to TF during training)<ul>
<li>required: tensor's data type</li>
<li>optional: shape, <tt class="docutils literal">None</tt> in one dimension means any size</li>
</ul>
</li>
<li>evaluate phase: pass a <tt class="docutils literal">feed_dict</tt> to <tt class="docutils literal">eval()</tt> that specifies the desired value.</li>
<li><strong>rank of a tensor</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Tensor">(Source)</a>: The <strong>order</strong> (also <strong>degree</strong> or <strong>rank</strong>) of a tensor is the dimensionality of the array
needed to represent it, or equivalently, the number of indices needed to label a component of that array.</li>
<li>you can feed any operations, not just <tt class="docutils literal">placeholder</tt></li>
<li>mini-batch approach:<ol class="arabic">
<li>set <span class="math">\(\mathbf{X}, \mathbf{y}\)</span>'s <tt class="docutils literal">Placeholder</tt></li>
<li>set <tt class="docutils literal">batch_size</tt>, <tt class="docutils literal">n_epochs</tt>, calculate <tt class="docutils literal">n_batches</tt>, select mini-batch randomly (generate a list of random numbers as indices, use these indices to pick the samples for the mini-batch).</li>
</ol>
</li>
</ul>
<div class="section" id="saving-and-restoring-models">
<h3>Saving and Restoring Models</h3>
<p>You can save model (parameters) to disk / restore the model from disk.</p>
<p>You can save <strong>checkpoint</strong> at regular intervals, in case the machine crushes when training the models.</p>
<p><strong>How to save a model?</strong></p>
<ol class="arabic simple">
<li>Create <tt class="docutils literal">Saver</tt> node at the end of the construction phase, after all variable nodes are created.</li>
<li>In execution phase, call <tt class="docutils literal">save()</tt> method to save the model, passing it the session and path of the checkpoint file.</li>
</ol>
<p><strong>How to restore a model?</strong></p>
<ol class="arabic simple">
<li>create a <tt class="docutils literal">Saver</tt> at the end of the construction phase</li>
<li>call <tt class="docutils literal">Saver</tt>'s <tt class="docutils literal">restore()</tt> method to initialize the variables at the beginning of the execution phase.</li>
</ol>
<p>In addition, you can specify which variables to save/restore and what names to use.</p>
<p><tt class="docutils literal">save()</tt> also saves the structure of the graph in a second file with the same name plus a <tt class="docutils literal">.meta</tt> extension.</p>
<ul class="simple">
<li><tt class="docutils literal">tf.train.import_meta_graph()</tt>: load graph structure, add it to default graph, it returns a <tt class="docutils literal">Saver</tt> instance that you can then use to restore the graph's state (i.e., variable values)</li>
</ul>
</div>
<div class="section" id="visualizing-the-graph-and-training-curves-using-tensorboard">
<h3>Visualizing the Graph and Training Curves Using TensorBoard</h3>
<p><strong>What can the TensorBoard do?</strong></p>
<ul class="simple">
<li>Feed it some training stats, it will display nice interactive visualizations of these stats in your web browser (e.g. learning curve)</li>
<li>Provide it the graph's definition to browse through it</li>
<li>What for?<ul>
<li>Identify errors in the graphs</li>
<li>Find bottlenecks</li>
</ul>
</li>
</ul>
<p><strong>How to use TensorBoard?</strong></p>
<ol class="arabic">
<li><p class="first">Write the graph definition and some training stats (e.g. MSE) to a log directory that TensorBoard will read from</p>
<ul class="simple">
<li>Use a different log directory every time you run your program or else TensorBoard will merge the stats from different runs.</li>
<li>Include timestamp in the log directory name is a good choice</li>
</ul>
</li>
<li><p class="first">Create a node in the graph that will evaluate the stats (e.g. MSE) value and write it to <em>a TensorBoard-compatible binary log string</em> called <strong>summary</strong>.</p>
</li>
<li><p class="first">Create a <tt class="docutils literal">FileWriter</tt> that you will use to write summaries to the log files in the log directory</p>
<ul class="simple">
<li>first parameter: path of the log directory (relative to the current directory)</li>
<li>second parameter: (optional) the graph you want to visualize</li>
<li><tt class="docutils literal">FileWriter</tt> writes the graph definition in a binary log file called an <strong>events file</strong></li>
</ul>
</li>
<li><p class="first">Update the execution phase to evaluate the <strong>summary</strong> node regularly during training. You can write its output (a summary) to the <strong>events file</strong> using <tt class="docutils literal">file_writer</tt></p>
</li>
<li><p class="first">Close the <tt class="docutils literal">file_writer</tt> at the end of the program.</p>
</li>
<li><p class="first">Fire up the TensorBoard server.</p>
<ol class="arabic">
<li><p class="first">Run TensorBoard on the log directory:</p>
<div class="highlight"><pre><span></span>$ tensorboard --logdir tf_logs/
</pre></div>
</li>
<li><p class="first">Open <tt class="docutils literal"><span class="pre">http://localhost:6006</span></tt></p>
<ul class="simple">
<li>Scalars Tab (e.g. learning curve)</li>
<li>Graphs Tab (Graph structure)<ul>
<li>The Nodes have many <strong>edges</strong> (connections), which are separated out to an auxiliary area on the right (to remove clutter).</li>
<li>Move a graph back and forth between the main graph and auxiliary area by right clicking on it</li>
<li>Double click to expand/collapse</li>
<li><tt class="docutils literal">show_graph()</tt> to show graph within <strong>Jupyter</strong></li>
</ul>
</li>
</ul>
</li>
</ol>
</li>
</ol>
</div>
<div class="section" id="name-scopes">
<h3>Name Scopes</h3>
<ul class="simple">
<li>Create <strong>name scopes</strong> to group related nodes.</li>
<li>Name of each operation: <tt class="docutils literal"><span class="pre">&lt;operation&gt;.op.name</span></tt></li>
</ul>
</div>
<div class="section" id="modularity">
<h3>Modularity</h3>
<ul class="simple">
<li><strong>ReLU</strong>: <span class="math">\(h_{\vec{w}, b}(\mathbf{X})=\mathrm{max}(\mathbf{X}\cdot \vec{w}+b, 0)\)</span></li>
<li>How to construct a subsystem to reduce redundancy.</li>
<li>Use name scope inside subsystem's definition to increase modularity.</li>
</ul>
</div>
<div class="section" id="sharing-variables">
<h3>Sharing Variables</h3>
<p><strong>How to share Variables among different operations?</strong></p>
<p>Approach 1: Pass Variables as arguments in methods.</p>
<p>Approach 2: Pass Variables in dictionaries in methods.</p>
<p>Approach 3: Set the shared variables as an attribute of the <tt class="docutils literal">relu()</tt> function upon the first call.</p>
<div class="highlight"><pre><span></span><span class="k">if</span> <span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">relu</span><span class="p">,</span> <span class="s1">&#39;threshold&#39;</span><span class="p">):</span>
  <span class="n">relu</span><span class="o">.</span><span class="n">threshold</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;threshold&#39;</span><span class="p">)</span>
</pre></div>
<p>Approach 4: (TF's option) Use <tt class="docutils literal">get_variable()</tt> function to create the shared variable if it does not exist yet, or reuse it if it already exists.</p>
</div>
</div>
<hr class="docutils" />
<div class="section" id="todo-rework-chapter-10-introduction-to-artificial-neural-networks">
<h2>TODO(rework): Chapter 10 - Introduction to Artificial Neural Networks</h2>
<p>Key idea that inspired <strong>Artificial Neural Networks (ANNs)</strong>: Look at the brain's architecture for inspiration on how to build an intelligent machine.</p>
<ul class="simple">
<li>ANN have gradually become quite different from their biological cousins, or we should drop the biological analogy altogether, lest we restrict our creativity to biologically plausible systems.</li>
<li>ANNs are at the very core of <strong>Deep Learning (DL)</strong>.</li>
</ul>
<div class="section" id="from-biological-to-artificial-neurons">
<h3>From Biological to Artificial Neurons</h3>
<p>A short history:</p>
<ul class="simple">
<li>(in 1943) The landmark paper <em>A Logical Calculus of Ideas Immanent in Neurons Activity</em> presented a simplified computational model of how biological neurons might work together in animal brains to perform complex computations
using <strong>propositional logic</strong>.</li>
<li>(until 1960s) Early success of ANNs led to the widespread belief that we would soon be conversing with truly intelligent machines. Then it became clear that
this promise would go unfulfilled (for quite a while, <strong>the dark era</strong>)</li>
<li>(in 1980) New arcitecture of ANN and better training techniques.</li>
<li>(in 1990) Powerful alternative ML techniques such as SVM were favored by most researchers.</li>
<li>(Now) Another wave of ANN:<ul>
<li>huge quantity of data available</li>
<li>ANN frequently outperform other ML techniques on very large and complex problems.</li>
<li>Increasingly computing power.</li>
<li>Improved training algorithms.</li>
<li>Some theoretical limitations of ANN have turned out to be benign in practice.</li>
<li>ANN seem to have entered a virtuous circle of funding and progress.</li>
</ul>
</li>
</ul>
<div class="section" id="biological-neurons">
<h4>Biological Neurons</h4>
<p><strong>biological neurons</strong></p>
<ul class="simple">
<li>Biological neurons receive short electrical impulses called <strong>signals</strong> from other neurons via these synapses.</li>
<li>When a neuron receives a sufficient number of signals from other neurons within a few milliseconds, it fires its own signals.</li>
<li>Individual biological neurons seem to behave in a rather simple way, but they are organized in a vast network of billions of neurons, each neuron typically connected
to thousands of other neurons. Highly complex computations can be performed by a vast network of fairly simple neurons. <strong>Biological Neuron Network (BNN)</strong></li>
<li>The architecture of BNN is still the subject of active research, but some parts of the brain have beed mapped. It seems that neurons are often organized in consecutive layers.</li>
</ul>
<p>Nomenclature</p>
<ul class="simple">
<li>cerebral</li>
<li>cortex</li>
<li>nucleus</li>
<li>dentrites</li>
<li>axon</li>
<li>telodendria</li>
<li>synaptic terminal (synapses): connected to the dendrites (or directly to the cell body) of other neurons</li>
</ul>
</div>
<div class="section" id="logical-computations-with-neurons">
<h4>Logical Computations With Neurons</h4>
<p><strong>An Artificial Neuron</strong> by Warren McCulloch and Walter Pitts (there are many types of artificial neurons).</p>
<ul class="simple">
<li>It is a simple model of the biological neuron.</li>
<li>Input: one/more binary input</li>
<li>Output: one binary output</li>
<li>Function: The neuron activates when more than a certain number of its inputs are active.</li>
<li>Network of them can compute any logical proposition you want.</li>
<li>You can add one input to inhibit the neuron's activity (shut it down).</li>
</ul>
</div>
<div class="section" id="the-perceptron">
<h4>The Perceptron</h4>
<p>The Proceptron [1957, Rosenblatt]</p>
<ul class="simple">
<li>is one of the simplest ANN architectures</li>
<li>based on an artificial neuron called <strong>linear threshold unit (LTU)</strong></li>
<li>in/out: real numbers. Each input connection is associated with a weight.</li>
<li>Behavior:<ul>
<li>The LTU computes a weighted sum of its input <span class="math">\(z = w_1x_1 + w_2x_2 + ... + w_nx_n = \vec{w}^T \cdot \vec{x}\)</span></li>
<li>Then apply a <strong>step function</strong> (the threshold) to that sum. Instances of the step functions are:<ul>
<li><strong>Heaviside step function</strong></li>
<li><strong>Sign function</strong></li>
</ul>
</li>
<li>Output the result <span class="math">\(h_{\vec{w}}(\vec{x}) = step(z) = step(\vec{w}^T \cdot \vec{x})\)</span></li>
</ul>
</li>
</ul>
<p><em>A single LTU computes simple linear binary classification (just like logistic regressor or a linear SVM)</em></p>
<p><strong>Training an LTU</strong> means find the right values for <span class="math">\(w_0\)</span> (weight for the extra bias feature), <span class="math">\(w_1, w_2, ..., w_n\)</span></p>
<p><strong>A Proceptron</strong> is composed of a <strong>single layer</strong> of LTUs (The name <em>Perceptron</em> is sometimes used to mean a tiny netowrk with a single LTU.)</p>
<ul class="simple">
<li><strong>Input neurons</strong>: special passthrough neurons, they just output whatever input they are fed.</li>
<li>Each neuron connected to all the <em>inputs</em></li>
<li>An extra bias feature added, represented using a special type of neuron - <strong>the bias neuron</strong>, which just outputs 1 all the time.</li>
<li>A proceptron can be (but not only) used as a multioutput classifier.</li>
</ul>
<p><strong>The training algorithm</strong></p>
<ul class="simple">
<li>proposed by Frank Rosenblatt, inspired by <strong>Hebb's Rule</strong> <a class="citation-reference" href="#hr10" id="id4">[hr10]</a></li>
<li>Training:<ol class="arabic">
<li>Perceptron is fed one training example at a time.</li>
<li>For each instance it makes its predictions.</li>
<li>For every output neuron that produced a wrong prediction, it reinforces the connection weights from the inputs that would have contributed to the correct prediction.</li>
</ol>
</li>
</ul>
<p>TODO: Equation</p>
<p>Decision boundary of each output neuron is linear. Perceptrons are incapable of learning complex patterns.</p>
<dl class="docutils">
<dt>Perceptron Convergence Theorem</dt>
<dd>If the training instances are <strong>linear separable</strong>, Rosenblatt demonstrated that this algorithm converges to a solution (not a unique solution)</dd>
</dl>
<p>Scikit-Learn provides a <code>Perceptron</code> class that implements a single LTU netowrk. TODO: code</p>
<p>Scikit-Learn's <code>Perceptron</code> is equivalent to <code>SGCClassifier</code> with the following hyperparameters:</p>
<ul class="simple">
<li><code>loss = &quot;perceptron&quot;</code></li>
<li><code>learning_rate = &quot;constant&quot;</code></li>
<li><code>eta0=1</code> (the learning rate)</li>
<li><code>penalty = None</code> (no regularization)</li>
</ul>
<p>Unlike logistic Regression, Perceptrons don't output a class probability.</p>
<p>In a 1969 monograph titled <em>Perceptrons</em>, by Marvin Minsky and Seymour Papert, several serious weaknesses of Perceptrons were mentioned, in particular the fact that incapable of solving some trivial problems (e.g. <strong>the Exclusive OR classification problem</strong>). Many reserchers dropped <strong>connectionism</strong> (i.e. the
study of NNs) altogether in favor of higher-level problems such as logic, problem solving, and search.</p>
<p>It turns out some of the limitations of Perceptrons can be eliminated by stacking multiple Perceptrons. The resulting NN: <strong>Multi-Layer Perceptron (MLP)</strong>. MLP can solve the XOR problem.</p>
</div>
</div>
<div class="section" id="multi-layer-perceptron-and-backpropagation">
<h3>Multi-Layer Perceptron and Backpropagation</h3>
<p>Composition of MLP:</p>
<blockquote>
<ul class="simple">
<li>one (passthrough) input layer</li>
<li>one or more layers of LTUs (hidden layer)</li>
<li>one final layer of LTUs (output layer)</li>
</ul>
<p>Every layer except the output layer includes a bias neuron and is fully connected to the next layer. When an ANN has two or more hidden layers, it is called a <strong>Deep Neural Network (DNN)</strong>.</p>
</blockquote>
<p>Many researchers struggled to find a way to train MLPs, failed.</p>
<p><a class="citation-reference" href="#rhw86" id="id5">[RHW86]</a> published Backpropagation training algorithm (today we describe it as Gradient Descent using reverse-mode autodiff).</p>
<dl class="docutils">
<dt>The Backpropagation Algorithm</dt>
<dd><ol class="first arabic simple">
<li>Forward Pass: for each training instance the backpropagation algorithm makes a prediction</li>
<li>Reverse Pass: measure the error, then goes through each layer in reverse to measure the error contribution from each connection.</li>
<li>Gradient Descent Step: slightly tweaks the connection weights to reduce the error.</li>
</ol>
<p class="last">In order for this algorithm to work properly, the authors make a key change to the MLP's architecture: they replaced the step function with the logistic function, <span class="math">\(\sigma (z)=\frac{1}{1+\exp{-z]}}\)</span>. This was essential because the step function contains only flat segments, so there is no gradient to work with, while the logistic function has a well-defined non zero derivative everywhere, allowing Gradient Descent to make some progress at every step. The backpropagation algorithm may be used with other <strong>activation functions</strong>,</p>
</dd>
</dl>
<p>Activation functions</p>
<blockquote>
<ul class="simple">
<li>logistic function</li>
<li>the hyperbolic tangent function. Its output value ranges from -1 to 1 (instead of 0 to 1 inthe case of the logistic function), which tends to make each layer's output more or less normalized (i.e., centered around 0) at the beginning of training. This often helps speed up convergence.</li>
<li>The ReLU function. It is continuous but unfortunately not differentiable at <code>z=0</code> (the slope changes abruptly, which can make Gradient Descent bounce around). However, in practice it works very well and has the advantage of being fast to compute. Most importantly, the face that it does not have a maximum output value also helps reduce some issues during Gradient Descent.</li>
</ul>
</blockquote>
<p>MLP is often used for classification, with each output neuron corresponds to a different binary class. For exclusive classes: the output layer is typically modified by replacing the individual activation functions by a shared <strong>softmax function</strong>. The output of each neuron corresponds to the
estimated probability of the corresponding class.</p>
<dl class="docutils">
<dt>Feedforward Neural Netowrk</dt>
<dd>NNs whose signal flows only in one direction (from the inputs to the outputs). e.g.: MLP.</dd>
</dl>
</div>
<div class="section" id="training-an-mlp-with-tf-s-high-level-api">
<h3>Training an MLP with TF's High-Level API</h3>
<p>The simplest way to tarin an MLP with TF is to use the high-level API <tt class="docutils literal">TF.Learn</tt>, which offers a Scikit-Learn-Compatible API.</p>
<p>The <tt class="docutils literal">DNNClassifier</tt> class makes it fairly easy to train a DNN with any number of hidden layers, and a softmax output layer to output estimated class probabilities.</p>
<ol class="arabic simple">
<li>Create a set of real valued columns from the training set, (othertypes of columns, such as categorical columns, are also available)<ol class="arabic">
<li>Creates all the neuronlayers, based on the ReLU activation function by default (<tt class="docutils literal">activation_fn</tt> hyperparameter)</li>
<li>Output layer relies on the softmax layer</li>
<li>Cost function is cross entropy</li>
</ol>
</li>
<li>Create the <tt class="docutils literal">DNNClassifier</tt>, and wrap it in a Scikit-Learn compatible helper</li>
<li>Prapare the dataset, scale with Scikit-Learn's <tt class="docutils literal">StandardScaler</tt></li>
<li>Run 40000 training iterations using batches of instances</li>
<li>Run this model</li>
</ol>
<p>Related code</p>
<ul class="simple">
<li><code>tf.contrib.learn.infer_real_valued_columns_from_input</code></li>
<li><code>tf.contrib.learn.DNNClassifier</code>, <code>tf.contrib.learn.SKCompat</code></li>
<li><code>dnn_clf.fit</code>, <code>dnn_clf.predict</code></li>
<li><code>sklearn.metrics.accuracy_score</code></li>
</ul>
<p><code>tensorflow.contrib</code> package contains many useful, experimental functions that  have not yet graduated to be part of the core TF API. Thy may change without notice in the future.</p>
</div>
<div class="section" id="training-a-dnn-using-plain-tf">
<h3>Training a DNN Using Plain TF</h3>
<p>If you want more control over the architecture of the network, you may prefer to use TF's lover-level Python API introduced in Chapter 9.</p>
<p>Here we will build the same model as before and implement MBGD to train it on the MNISt dataset.</p>
<div class="section" id="construction-phase">
<h4>Construction Phase</h4>
<ol class="arabic">
<li><p class="first">Import tensorflow, specify the number of inputs/outpus and set the number of hidden neurons in each layers.</p>
</li>
<li><p class="first">Use <tt class="docutils literal">placeholder</tt> nodes to represent the training data and targets. The shape of <tt class="docutils literal">X</tt> is a 2D tensor (matrix) with instances along the first dimension and features along the second dimension.
Since we know the number of features is going to be 28x28 and we don't knoow yet how many instances each training batch will contain. So the shape of <tt class="docutils literal">X</tt> is <tt class="docutils literal">(None, n_inputs)</tt>. Shape of <tt class="docutils literal">y</tt> is <tt class="docutils literal">(None)</tt></p>
</li>
<li><p class="first">Create the actual NN</p>
<ul>
<li><p class="first"><tt class="docutils literal">X</tt> act as the input layer</p>
</li>
<li><p class="first">create two hidden layers (with ReLU as activation function) and the output layer (softmax as activation function)</p>
</li>
<li><p class="first">create a function <tt class="docutils literal">neuron_layer()</tt> to create one layer at a time. It needs parameters to specify the inputs, the number of neurons, the activation function, and the name of the layer.</p>
<ol class="arabic">
<li><p class="first">create a name scope using the name of the layer</p>
</li>
<li><p class="first">get number of inputs by looking up the input matrix's shape (the second dimension)</p>
</li>
<li><p class="first">create a variable <tt class="docutils literal">W</tt> holding the weights matrix (often called <strong>the layer's kernel</strong>). It's a 2D tensor containing all the connection weights between each input and each neuron,
hence it's shape is <tt class="docutils literal">(n_inputs, n_neurons)</tt>.</p>
<p>It will be initialized randomly, using a <strong>truncated normal (Gaussian) distribution</strong> with a standard deviation of <span class="math">\(\frac{2}{\sqrt{n_{inputs}}}\)</span>.
Using this specific standard deviation helps the algorithm converge much faster.</p>
<p>It's important to initialze connection weights randomly for all hidden layers to <strong>avoid any symmetries that the Gradient Descent algorithm would be unable to break</strong> <a class="citation-reference" href="#tsi10" id="id6">[tsi10]</a></p>
</li>
<li><p class="first">create a <tt class="docutils literal">b</tt> variable for biases, initialized to 0 (no symmetry issue in this case), with one bias parameter per neuron.</p>
</li>
<li><p class="first">create a subgraph to compute <span class="math">\(\mathbf{Z}=\mathbf{X} \cdot \mathbf{W} + b\)</span>.
This vectorized implementation will compute the weighted sums of the inputs plus the bias term for each and every neuron in the layer, <strong>for all the instances in the batch in just one shot</strong>.</p>
</li>
</ol>
</li>
</ul>
</li>
</ol>
<table class="docutils citation" frame="void" id="hr10" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id4">[hr10]</a></td><td><strong>The Hebb's rule</strong>, or <strong>Hebbian Learning</strong>: When a biological neuron often triggers another neuron, the connection between these two neurons grows stronger. In other words, the connection
weight between two neurons is increased whenever they have the same output.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tsi10" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6">[tsi10]</a></td><td><strong>The Symmetry Issue</strong>: For example, if you set all the weights to 0, then all neurons will output 0, and the error gradient will be the same for all neurons in a given hidden layer. The
Gradient Descent step will then update all the weights in exactly the same way in each layer, so they will all remain equal. In other words, despite having hundreds
of neurons per layer, your model will act as if there were only one neuron per layer.</td></tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="rhw86" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id5">[RHW86]</a></td><td>&quot;Learning Internal Representations by Error Propagation&quot;, D. Rumelhart, G. Hinton, R. Williams (1986).</td></tr>
</tbody>
</table>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="chapter-11-training-deep-neural-networks">
<h2>Chapter 11 - Training Deep Neural Networks</h2>
<p>Some problems when you're training a DNN:</p>
<ol class="arabic simple">
<li>Vanishing and exploding gradients: affects DNNs and makes lower layers very hard to train.</li>
<li>Extremly slow training - The Optimizers</li>
<li>A model with millions of parameters would severely risk overfitting the training set - The Regularization techniques for large NNs.</li>
</ol>
<div class="section" id="vanishing-exploding-gradients-problems">
<h3>Vanishing/Exploding Gradients Problems</h3>
<p>In the backpropagation algorithm, it works by going from the output layer to the input layer, propagating the <em>error gradient</em> on the way. Once
the algo has computed <em>the gradient of the cost function w.r.t. each parameter in the network</em>, it uses these gradients to update each parameter
with a gradient descent step.</p>
<ul class="simple">
<li><strong>The vanishing gradients problem</strong>: gradients sometimes get smaller and smaller as the algorithm progresses down to the lower layers. As a result,
the Gradient Descent update leaves the lower layer connection weights virtually unchanged, and training never converges to a good solution.</li>
<li><strong>The exploding gradients problem</strong>: in some cases, the opposite can happen: the gradients can grow bigger and bigger, so many layers get insanely
large weight updates and the algorithm diverges, which is mostly encountered in recurrent NNs.</li>
<li>More generally, DNNs suffer from unstable gradients, different layers may learn at widely different speeds.</li>
<li>It is one of the reasons why DNN were mostly abandoned for a long time. It is only around 2010 that significant progress was made in understanding it (check out the paper <cite>&quot;Understanding the Difficulty of Training Deep Feedforward Neural Networks&quot;</cite> <a class="citation-reference" href="#gb10" id="id7">[GB10]</a>)</li>
</ul>
<p>TODO: Interesting Observations</p>
<div class="section" id="xavier-and-he-initialization">
<h4>Xavier and He Initialization</h4>
<p>In their paper, Glorot and Bengio proposed a way to significantly alleviate this problem: we want the signal to flow properly in both directions:</p>
<ul class="simple">
<li>Forward direction when making predictions, and</li>
<li>In the backward direction, when backpropagating gradients. We don't want the signal to die out, nor do we want it to explode and saturate.</li>
</ul>
<p>For the signal to flow properly, the authors argue that we need the variance of the outputs of each layer to be equal to the variance of its inputs, and we
also need the gradients to have equal variance before and after flowing through a layer in the reverse direction. It is actually not possible to guarantee both unless the layer has an equal number of input and output connections, but they proposed a good compromise that
has proven to work very well in practice: the connection weights must be initialized randomly as described in [TODO equation 11-1], where <span class="math">\(n_{\text{inputs}}\)</span> are the number of input and output connections for the layer whose weights are
being initialized (called <strong>fan-in</strong> and <strong>fan-out</strong>). This initialization strategy is often called <strong>Xavier initialization</strong> or <strong>Glorot initialization</strong>.</p>
<p><em>fan-in</em> and <em>fan-out</em>, in the context of a fully connected layer:</p>
<ul class="simple">
<li>fan-in: the number of output neurons of the previous layer</li>
<li>fan-out: the number of output neurons of itself</li>
</ul>
<p><strong>Xavier initialization (when using the logistic activation function)</strong>:</p>
<div class="math">
\begin{align*}
      \text{Normal distribution with mean 0 and standard deviation } \sigma = \sqrt{\frac{2}{n_{inputs}+n_{outputs}}} \\
\text{Or a uniform distribution between } -r \text{ and } +r \text{, with } r=\sqrt{\frac{6}{n_{inputs}+n_{outputs}}}
\end{align*}
</div>
<p>Using the Xavier initialization strategy can speed up training considerably, and it is one of the tricks that led to the current success of DL.</p>
<p><strong>Some recent papers have provided similar strategies for different activation functions</strong>:</p>
<ul class="simple">
<li>Logistic function</li>
<li>Hyperbolic tangent function</li>
<li>ReLU (and its variants)</li>
</ul>
<p>TODO: Table 11-1</p>
<dl class="docutils">
<dt><strong>He Initialization</strong></dt>
<dd>He Initialization is used for ReLU and its variants. It considers only the fan-in, not the average between fan-in and fan-out like in Xavier initialization.
It is also the default for the <tt class="docutils literal">train.contrib.layers.variance_scaling_initializer()</tt> function, but you can change this by setting the argument <tt class="docutils literal">mode = &quot;FAN_AVG&quot;</tt>.</dd>
</dl>
<div class="highlight"><pre><span></span><span class="n">he_init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">variance_scaling_initializer</span><span class="p">()</span>
<span class="n">hidden1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_hidden1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">kernel_initializer</span><span class="o">=</span><span class="n">he_init</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;hidden1&quot;</span><span class="p">)</span>
</pre></div>
<p>By default <tt class="docutils literal">tf.layers.dense()</tt> uses Xavier initialization with a uniform distribution.</p>
</div>
<div class="section" id="nonsaturating-activation-functions">
<h4>Nonsaturating Activation Functions</h4>
<p>The paper <a class="citation-reference" href="#gb10" id="id8">[GB10]</a> gave some insights, one of them was that the vanishing/exploding gradient problems were in part due to a poor choice of activation function.</p>
<p>It turns out that other activation functions behave much better in DNNs, in particular the ReLU function, mostly because it does not saturate for positive values and also fast to compute.</p>
<p>But the ReLU is not perfect. It suffers from a problem known as <strong>the dying ReLU</strong> <a class="citation-reference" href="#tdr11" id="id9">[tdr11]</a>. To solve this problem, you may want to use a variant of the ReLU function, such as <strong>the leaky ReLU</strong> <a class="citation-reference" href="#tlr11" id="id10">[tlr11]</a>. This
small slope ensures that leaky ReLUs never die; they can go into a long coma, but they have a chance to eventually wake up.</p>
<p>The paper <a class="citation-reference" href="#xwcl15" id="id11">[XWCL15]</a> compared several variants of the ReLU and one of its conclusions was that <strong>the leaky variants always outperformed the strict ReLU</strong>. In face, setting <span class="math">\(\alpha = 0.2\)</span> (huge leak) seemed to
result in better performance than <span class="math">\(\alpha = 0.01\)</span> (small leak). They also evaluate <strong>the randomized ReLU (RReLU)</strong> <a class="citation-reference" href="#trr11" id="id12">[trr11]</a>. It also performed fairly well and seemed to act as a regularizer (reducing the risk of overfitting the training set).
Finally they also evaluated <strong>the parametric ReLU (PReLU)</strong> <a class="citation-reference" href="#tpr11" id="id13">[tpr11]</a>. This was reported to strongly outperform ReLU on large image datasets, but on smaller datasets it has the risk of overfitting the training set.</p>
<p>The paper <a class="citation-reference" href="#cuh15" id="id14">[CUH15]</a> proposed a new activation function called the <strong>exponential linear unit (ELU)</strong> that outperformed all the ReLU variants in their experiments: training time was reduced and the NN performed better on the test set.</p>
<div class="math">
\begin{equation*}
      \text{ELU activation function}:
\mathrm{ELU}_\alpha (z) = \left\{
                              \begin{array}{ll}
                                \alpha ( \mathrm{exp}(z) - 1), \text{ if } z &lt; 0 \\
                                z, \text{ if } z \ge 0
                              \end{array}
                          \right.
\end{equation*}
</div>
<p>ELU is similar to ReLU, with a few differences:</p>
<ol class="arabic simple">
<li>It has negative output regions, whch allows the unit to have an average output closer to 0. Thus helps alleviate the vanishing gradients problem.</li>
<li>It has a non-zero gradient for <span class="math">\(z &lt; 0\)</span>, which avoids the dying units issue.</li>
<li>The function is smooth everywhere, including around <span class="math">\(z = 0\)</span>, which helps speed up gradient descent, since it doesn't bounce as much left and right of <span class="math">\(z = 0\)</span></li>
<li>Main drawback of ELU: slower to compute than the ReLU and its variants, but during training this is compensated by the faster convergence rate. But at test time an ELU network will be slower than a ReLU network.</li>
<li><strong>Which activation function should you use for the hidden layers?</strong> In the book.</li>
</ol>
<p>TF has a predefined ELU: <tt class="docutils literal">tf.nn.elu</tt>.</p>
<p>TF doesn't have a predefined leaky ReLU.</p>
</div>
<div class="section" id="batch-normalization-bn">
<h4>Batch Normalization (BN)</h4>
<p>Using He initialization along with ELU (or ReLU variants) can reduce the vanishing/exploding gradient problem at the beginning of training, it doesn't guarantee that they won't come back during training.</p>
<p><a class="citation-reference" href="#is15" id="id15">[IS15]</a> proposed a technique called <strong>Batch Normalization</strong> to address the vanishing/exploding gradients problems, and more generally the problem that the distribution of each layer's inputs changes during training, as the parameters of the previous layers
change (which they call the <strong>Internal Covariate Shift</strong> problem).</p>
<p>The technique consists of adding an operation in the model just before the activation function of each layer, simply zero-centering and normalizing the inputs, then scaling and shifting the result using two new parameters per layer (one for scaling, the other for shifting).
This operation lets the model learn the optimal scale and mean of the inputs for each layer.</p>
<p>In order to zero-center and nomalize the inputs, the algo estimate the inputs' mean and standard deviation by evaluating the mean and standard deviation of the inputs over the current mini-batch.</p>
<p>TODO: Equation 11-3</p>
<p><strong>smoothing term</strong>: <span class="math">\(\epsilon\)</span>, avoid division by zero (typically <span class="math">\(10^{-5}\)</span>).</p>
<p>In total, four parameters are learned for each batch-normalized layer:</p>
<ol class="arabic simple">
<li><strong>scaling parameter</strong> <span class="math">\(\gamma\)</span>,</li>
<li><strong>shifting parameter</strong> <span class="math">\(\beta\)</span> (offset),</li>
<li><strong>empirical mean</strong> <span class="math">\(\mu\)</span>, evaluated over the whole mini-batch, TODO: exponential decay</li>
<li><strong>standard deviation</strong> <span class="math">\(\sigma\)</span>, evaluated over the whole mini-batch</li>
</ol>
<p>Output of the Batch Normalization operation: a scaled and shifted version of the inputs.</p>
<p>At test time, there is no mini-batch to compute the empirical mean and standard deviation, so instead you simply use the whole training set's mean and standard deviation.
These are typically efficiently computed during training using a moving average.</p>
<p>TODO: Ad-/Disadvantages</p>
<div class="section" id="implementing-batch-normalization-with-tensorflow">
<h5>Implementing Batch Normalization with TensorFlow</h5>
<p>TF provides a <tt class="docutils literal">tf.nn.batch_normalization()</tt> function that simply centers and normalizes the input, but you must compute the mean and standard deviation yourself (based on the mini-batch data during training or on the full dataset during testing) and
pass them as parameters to this function, and you must also handle the creation of the scaling and offset parameters (and pass them to this function). But the most convenient approache is, instead, to use <tt class="docutils literal">tf.layers.batch_normalization()</tt> function,
which handels all this for you: <code>training = tf.placeholder_with_default(False, shape=(), name='training')</code>, default is <tt class="docutils literal">False</tt>, we will set it to <tt class="docutils literal">True</tt> during training <em>at each training operation</em>. This will be used to tell the <code>tf.layers.batch_normalization()</code>
function whether it should use the current mini-batch's mean and standard deviation (during training) or the whole training set's mean and standard deviation (during testing).</p>
<p><code>tf.layers.dense()</code> doesn't apply any activation function by default.</p>
<p>The BN algorithm: <code>tf.layers.batch_normalization(prev_layer, training, momentum)</code>, uses <strong>exponential decay</strong> to compute the moving averages, which is why it requires the <code>momentum</code> parameter:</p>
<dl class="docutils">
<dt><strong>Exponential Decay</strong></dt>
<dd><p class="first">Given a new value <span class="math">\(v\)</span>, the running average <span class="math">\(\hat{v}\)</span> is updated through the equation:</p>
<div class="math">
\begin{equation*}
\hat{v} \leftarrow \hat{v} \times \text{ momentum } + v \times (1 - \text{ momentum })
\end{equation*}
</div>
<p class="last">A good momentum value is typically close to 1 - for example, 0.9, 0.99, or 0.999 (you want more 9s for larger datasets and smaller mini-batches).</p>
</dd>
</dl>
<p>You can use the <code>partial()</code> function from the <code>functools</code> module to reduce repetitions:</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="n">my_batch_norm_layer</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">batch_normalization</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">hidden1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_hidden1</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;hidden1&quot;</span><span class="p">)</span>
<span class="n">bn1</span> <span class="o">=</span> <span class="n">my_batch_norm_layer</span><span class="p">(</span><span class="n">hidden1</span><span class="p">)</span>
</pre></div>
<p><strong>The execution phase</strong>: pretty much the same but with two exceptions:</p>
<ol class="arabic simple">
<li>During training, whenever you run an operation that depends on the <code>batch_normalization()</code> layer, you need to set the <code>training</code> placeholder to <code>True</code> .</li>
<li>The <code>batch_normalization()</code> function creates a few operations that must be evaluated at each step during training in order to update the moving avrages (recall that these moving averages are needed to evaluate the training set's mean and standard deviation). These operations are automatically added to the <code>UPDATE_OPS</code> collection, so all we need to do is get the list of operations in the collection and run them at each training iteration.</li>
</ol>
<div class="highlight"><pre><span></span><span class="n">extra_update_ops</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">UPDATE_OPS</span><span class="p">)</span>
<span class="c1"># ...</span>
<span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">([</span><span class="n">training_op</span><span class="p">,</span> <span class="n">extra_update_ops</span><span class="p">],</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">training</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">y_batch</span><span class="p">})</span>
<span class="c1"># ...</span>
<span class="n">accuracy_val</span> <span class="o">=</span> <span class="n">accuracy</span><span class="o">.</span><span class="n">eval</span><span class="p">(</span><span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">images</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span><span class="n">mnist</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">labels</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="section" id="gradient-clipping">
<h4>Gradient Clipping</h4>
<p>Popular technique to lessen the exploding gradients problem: simply clip the gradients during backpropagation so that they never exceed some threshold -&gt; Gradient Clipping</p>
<p>In general people new prefer Batch Normalization. But it's useful to know about Gradient Clipping and How to implement it.</p>
<p>In TF, the optimizer's <code>minimize()</code> function takes care of both computing the gradients and applying them, so you must first</p>
<ol class="arabic simple">
<li>call the optimizer's <code>compute_gradients()</code> method, then</li>
<li>create an operation to clip the gradients using the <code>clip_by_value()</code> function, and finally</li>
<li>create an operation to apply the clipped gradients using the optimizer's <code>apply_gradients()</code> method</li>
</ol>
<div class="highlight"><pre><span></span><span class="c1"># This code compute the gradients, clip them between `-threshold` and `threshold`, and apply them. The `threshold` is a hyperparameter you can tune.</span>
<span class="n">grads_and_vars</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">compute_gradients</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
<span class="n">capped_grads</span> <span class="o">=</span> <span class="p">[(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">grad</span><span class="p">,</span> <span class="o">-</span><span class="n">threshold</span><span class="p">,</span> <span class="n">threshold</span><span class="p">),</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span><span class="p">,</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">grads_and_vars</span><span class="p">]</span>
<span class="n">training_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">capped_grads</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="reusing-pretrained-layers">
<h3>Reusing Pretrained Layers</h3>
<p>It is generally not a good idea to train a very large DNN from scratch: instead, you shold always try to find an existing NN that accomplishes a similar task to the one you're trying to
tackle, then just reuse the lower layers of this network: this is called <strong>transfer learning</strong>. It will not only speedup training considerably, but will also require much less training data.</p>
<p>You perhaps need to add a preprocessing step to resize the images to the size expected by the original model.</p>
<p>More generally, transfer learning will only work well if the inputs have similar low-level features.</p>
<div class="section" id="reusing-a-tensorflow-model">
<h4>Reusing a TensorFlow Model</h4>
<p>If the model was trained using TF, you can simply restore it and train it on the new task.</p>
<p><code>import_meta_graph()</code> function imports the operations (graph architecture) into the default graph. Then returns a <code>Saver</code> that you can later use to load the model's state: <code>saver = tf.train.import_meta_graph(&quot;./my_final_model.ckpt.meta&quot;)</code>.</p>
<p>You must then get a handle on the operations and tensors you will need for training:</p>
<div class="highlight"><pre><span></span><span class="n">default_graph</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">default_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s2">&quot;X:0&quot;</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">default_graph</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s2">&quot;y:0&quot;</span><span class="p">)</span>
<span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span><span class="o">.</span><span class="n">get_tensor_by_name</span><span class="p">(</span><span class="s2">&quot;eval/accuracy:0&quot;</span><span class="p">)</span>
<span class="n">training_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span><span class="o">.</span><span class="n">get_operation_by_name</span><span class="p">(</span><span class="s2">&quot;GradientDescent&quot;</span><span class="p">)</span>
</pre></div>
<p>The name of a tensor is the name of the operation that outputs it followed by <code>:0</code> (if it is the first output).</p>
<p>If the pretrained model is not well documented, you need to explore the graph to find the names of the operations you will need</p>
<ul>
<li><p class="first">You can explore the graph using TensorBoard (first export the graph using a <code>FileWriter</code>)</p>
</li>
<li><p class="first">You can use the graph's <code>get_operations()</code> to list all the operations.</p>
<div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_default_graph</span><span class="p">()</span><span class="o">.</span><span class="n">get_operations</span><span class="p">():</span>
  <span class="k">print</span><span class="p">(</span><span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
</pre></div>
</li>
</ul>
<p>If you are the author of the original model, you should give operations very clear names and document them. Another approach: create a collection containing all the important operations that people
will want to get a handle on:</p>
<div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">op</span> <span class="ow">in</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">,</span> <span class="n">trainin_op</span><span class="p">):</span>
  <span class="n">tf</span><span class="o">.</span><span class="n">add_to_collection</span><span class="p">(</span><span class="s2">&quot;my_important_ops&quot;</span><span class="p">,</span> <span class="n">op</span><span class="p">)</span>
</pre></div>
<p>Reuse: <code>X, y, accuracy, training_op = tf.get_collection(&quot;my_important_ops&quot;)</code></p>
<p>Restore the model's state using the <code>Saver</code> and continue training using your own data.</p>
<div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
  <span class="n">saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&quot;./my_model_final.ckpt&quot;</span><span class="p">)</span>
  <span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="c1"># train the model on your own data</span>
</pre></div>
<p>Alternatively, you can use the code that build the original graph if you have access to it, instead of <code>import_meta_graph()</code>.</p>
<p>In general, you will want to reuse only part of the original model, typically the lower layers. You can ignore the pretrained higher layers, build new layers on top of a pretrained layer, compute the loss for this new output,
and create an optimizer to minimize that loss.</p>
<p>If you have access to the pretrained graph's Python code, you cann just reuse the parts you need and chop out the rest. However, in this case you need a <code>Saver</code> to restore the pretrained model (specifying which variables you want to restore;
otherwise, TensorFlow will complain that the graphs do not match), and another <code>Saver</code> to save the new model.</p>
<div class="highlight"><pre><span></span><span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="c1"># build the new model with the same hidden layers 1-3 as before</span>

<span class="n">reuse_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">GLOBAL_VARIABLES</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s2">&quot;hidden[123]&quot;</span><span class="p">)</span> <span class="c1"># regular expression</span>
<span class="n">reuse_vars_dict</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">({(</span><span class="n">var</span><span class="o">.</span><span class="n">op</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">var</span><span class="p">)</span> <span class="k">for</span> <span class="n">var</span> <span class="ow">in</span> <span class="n">reuse_vars</span><span class="p">]})</span>
<span class="n">restore_saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">(</span><span class="n">reuse_vars_dict</span><span class="p">)</span> <span class="c1"># to restore layers 1-3</span>

<span class="n">init</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="p">()</span> <span class="c1"># to init all variables, old and new</span>
<span class="n">saver</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">Saver</span><span class="p">()</span> <span class="c1"># to save the new model</span>

<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
  <span class="n">init</span><span class="o">.</span><span class="n">run</span><span class="p">()</span>
  <span class="n">restore_saver</span><span class="o">.</span><span class="n">restore</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&quot;./my_model_final.ckpt&quot;</span><span class="p">)</span>
  <span class="p">[</span><span class="o">...</span><span class="p">]</span> <span class="c1"># train the model</span>
  <span class="n">save_path</span> <span class="o">=</span> <span class="n">saver</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">sess</span><span class="p">,</span> <span class="s2">&quot;./my_new_model_final.ckpt&quot;</span><span class="p">)</span>
</pre></div>
<p>First we build the new model by copying the original model's hidden layers 1 to 3. Then we get the list of all variables in hidden layers 1 to 3, using the regular expression <code>&quot;hidden[123]&quot;</code>. Next, we create a dictionary that maps the name of
each variable in the original model to its name in the new model (generally you want to keep the exact same names). Then we create a <code>Saver</code> that willrestore only these variables. We also create an operation to initialize all the variables
(old and new) and a second <span class="math">\(Saver\)</span> to save the entire new model, not just layers 1 to 3. We then start a session and initialize all variables in the model, then restore the variable values from the original model's layers 1 to 3.
Finally, we train the model on the new task and save it.</p>
</div>
<div class="section" id="reusing-models-from-other-frameworks">
<h4>Reusing Models from Other Frameworks</h4>
<p>TODO</p>
</div>
<div class="section" id="freezing-the-lower-layers">
<h4>Freezing the Lower Layers</h4>
<p>It is likely that the lower layers of the first DNN have learned to detect low-level features in pictures that will be useful across both image classification tasks, so you can just reuse these layers as they are. It is generally a good idea
to &quot;freeze&quot; their weights when training the new DNN: if the lower-layer weights are fixed, then the higher layer weights will be easier to train (because they won't have to learn a moving target). To freeze the lower layers:</p>
<ul>
<li><p class="first">Solution 1: give the optimizer the list of variables to train, excluding the variables form the lower layers.</p>
<div class="highlight"><pre><span></span><span class="n">train_vars</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">TRAINABLE_VARIABLES</span><span class="p">,</span> <span class="n">scope</span><span class="o">=</span><span class="s2">&quot;hidden[34]|outputs&quot;</span><span class="p">)</span>
<span class="n">training_op</span> <span class="o">=</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">var_list</span><span class="o">=</span><span class="n">train_vars</span><span class="p">)</span>
</pre></div>
<ol class="arabic simple">
<li>Get the list of all trainable variables in hidden layers 3 and 4 and in the output layer. This leaves out the variables in the hidden layers 1 and 2.</li>
<li>We provide this restricted list of trainable variables to the optimizer's <code>minimize()</code> function.</li>
</ol>
</li>
<li><p class="first">Solution 2: add a <code>tf.stop_gradient()</code> layer in the graph. Any layer below (in the sense of NN structure) it will be frozen.</p>
<p><code>hidden2_stop = tf.stop_gradient(hidden2)</code></p>
</li>
</ul>
</div>
<div class="section" id="caching-the-frozen-layers">
<h4>Caching the Frozen Layers</h4>
<p>Cache the output of the topmost frozen layer for each training instance. This will give you huge speed boost as you will only need to go through the frozen layers one per training instance (instead of once per epoch), assuming you have enough RAM.
Then during training, you would build batches of outputs from hidden layer 2 and feed them to the training operation.</p>
<div class="highlight"><pre><span></span><span class="n">h2_cache</span> <span class="o">=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">hidden2</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">images</span><span class="p">})</span>
<span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_epochs</span><span class="p">):</span>
  <span class="n">shuffled_idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">num_examples</span><span class="p">)</span>
  <span class="n">hidden2_batches</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">h2</span><span class="o">.</span><span class="n">cache</span><span class="p">[</span><span class="n">shuffled_idx</span><span class="p">],</span> <span class="n">n_batches</span><span class="p">)</span>
  <span class="n">y_batches</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array_split</span><span class="p">(</span><span class="n">mnist</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">shuffled_idx</span><span class="p">],</span> <span class="n">n_batches</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">hidden2_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">hidden2_batches</span><span class="p">,</span> <span class="n">y_batches</span><span class="p">):</span>
    <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">training_op</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">hidden2</span><span class="p">:</span> <span class="n">hidden2_batch</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">y_batch</span><span class="p">})</span>
</pre></div>
</div>
<div class="section" id="tweaking-dropping-or-replacing-the-upper-layers">
<h4>Tweaking, Dropping, or Replacing the Upper Layers.</h4>
<p>The output layer of the original model should usually be replaced since it is most likely not useful at all for the new task, and it may not even have the right number of outputs for the new task.</p>
<p>Similarly, the upper hidden layers of the original model are less likely to be as useful as the lower layers, since the high-level features that are most useful for the new task may differ significantly from the ones that were most useful for the
original task. You want to find the right number of layers to reuse.</p>
<p>Try freezing all the copied layers first, then train your model and see how it performs. Then try unfreezing one or two of the top hidden layers to let backpropagation tweak them and see if performance improves. The more training data you have, the more
layers you can unfreeze.</p>
<p>If you still cannot get good performance, and you have little training data, try dropping the top hidden layer(s) and freeze all remaining hidden layers again. You can iterate until you find the right number of layers to reuse. If you have plenty of training data,
you may try replacing the top hidden layers indtead of dropping them, and even add more hidden layers.</p>
<p>Try freezing ...</p>
<p>If you still ...</p>
</div>
<div class="section" id="model-zoos">
<h4>Model Zoos</h4>
<p>Where can you find a NN trained for a task similar to the one you want to tackle?</p>
<ol class="arabic simple">
<li>Your own catelog of models</li>
<li>Search in the <strong>model zoo</strong>. Many people train ML models for various tasks and kindly release their pretrained models to the public<ul>
<li>TF's own model zoo: <a class="reference external" href="https://github.com/tensorflow/models">https://github.com/tensorflow/models</a>, VGG, Inception, ResNet &amp; Tools to download popular image Datasets.</li>
<li>Caffe's Model Zoo. There is a converter: <em>caffe-tensorflow</em>.</li>
</ul>
</li>
</ol>
</div>
<div class="section" id="unsupervised-pretraining">
<h4>Unsupervised Pretraining</h4>
<p>You want to tackle a complex task for which you don't have much labeled training data, but unfortunately you cannot find a model trained on a similar task.</p>
<p>You can perform <strong>unsupervised pretraining</strong>, that is, if you have plenty of unlabeled training data, you can try to train the layers one by one, starting with the lowest layer and then going up, using an unsupervised feature detector algorithm
such as <strong>Restricted Boltzmann Machine (RBM)</strong> or autoencoders. Each layer is trained on the output of the previously trained layers (all layers except the one being trained are frozen). Once all layers have been trained this way, you can
fine-tune the network using supervised learning (i.e., with Backpropagation).</p>
<p>It is this technique that Geofferey Hinton and his team used in 2006 and which led to the revival of NNs and the success of Deep Learning. Until 2010, unsupervised pretraining (typically using RBMs) was the norm for deep nets, and it was only
after the vanishing gradients problem was alleviated that it became much more common to train DNNs purely using backpropagation.</p>
<p>However, unsupervised pretraining (today typically using autoencoders rather than RBMs) is still a good option when you have a complex task to solve, no similar model you can reuse, and only little labeled training data but plenty of unlabeled data.</p>
<p>Another option is to come up with a supervised task for which you can easily gather a lot of labeled training data, then use transfer learning.</p>
</div>
<div class="section" id="pretraining-on-an-auxiliary-task">
<h4>Pretraining on an auxiliary task</h4>
<p>One last option is to train a first NN on an auxiliary task for which you can easily obtain or generate labeled training data, then reuse the lower layers of that network for your actual task. The first NN's lower layers will learn feature
detectors that will likely be reusable by the second NN.</p>
<p>For example, if you want to build a system to recognize faces, you may only have a few pictures of each individual - clearly not enough to train a good classifier. Gathering hundreds of pictures of each person would not be practical. However,
you could gather a lot of pictures of random people on the internet and train a first NN to detect whether or not two different pictures the same person. Such a network would learn good feature detectors for faces,
so reusing its lower layers would allow you to train a good face classifier using little training data.</p>
<p>It is often rather cheap to gather unlabeled training examples, but quite expensive to label them. In this situation, a commmon technique is to label all your training examples as &quot;good&quot;, then generate many new training instances by corrupting
the good ones, and label these corrupted instances as &quot;bad&quot;. Then you can train a first NN to classify instances as good or bad. For example, you could download millions of sentences, label them as &quot;good&quot;, then randomly change a word in each
sentence and label the resulting sentences as &quot;bad&quot;. If a NN can tell that &quot;The dog sleeps&quot; is a good sentence but &quot;The dog they&quot; is bad, it probably knows quite a lot about language. Reusing its lower layers will likely help in many language
processing tasks.</p>
<p>Another approache is to train a first NN to output a score for each training instance, and use a cost function that ensures that a good instance's score is greater than a bad instance's score by at least some margin. This is called <strong>max margin learning</strong>.</p>
</div>
</div>
<div class="section" id="faster-optimizers">
<h3>Faster Optimizers</h3>
<p>4 wyas to speed up training so far:</p>
<ol class="arabic simple">
<li>apply a good initialization strategy for the connection weights.</li>
<li>use a good activation function</li>
<li>use batch normalization</li>
<li>reuse parts of a pretrained network</li>
</ol>
<p>Now, the fifth element: use a fast optimizer: Momentum optimization, Nesterov Accelerated Gradient, AdaGrad, RMSProp, Adam optimization.</p>
</div>
<div class="section" id="avoid-overfitting-through-regularization">
<h3>Avoid Overfitting Through Regularization</h3>
<p>DNNs has so many parameters that it has an incredible amount of freedom and can fit a huge variety of complex datasets. But this great flexibility also means that it prone to overfitting the training set.</p>
<div class="section" id="early-stopping">
<h4>Early Stopping</h4>
<p>Interrupt the training when its performance on the validation set starts dropping.</p>
<p>One way to implement this in TF: evaluate a model on a validation set at regular intervals (e.g., every 50 steps), and save a &quot;winner&quot; snapshot if it outperforms previous &quot;winner&quot; snapshots. Count the number of
steps since the last &quot;winnner&quot; snapshot was saved, and interrupt training when this number reaches some limit (e.g., 2000 steps). Then restore the last &quot;winner&quot; snapshot.</p>
<p>You can usually get even much higher performance by combining early stopping with other regularization techniques.</p>
</div>
<div class="section" id="l-1-and-l-2-regularization">
<h4><span class="math">\(l_1\)</span> and <span class="math">\(l_2\)</span> Regularization</h4>
<p>You can use <span class="math">\(l_1\)</span> and <span class="math">\(l_2\)</span> regularization to constrain a NN's connection weights (but typically not on its biases), like you did in chapter 4 for simple linear models.</p>
<p>One way to do this using TF is to simply add the approapriate regularization terms to your cost function.</p>
<p><span class="math">\(l_1\)</span>-Regularization:</p>
<div class="highlight"><pre><span></span><span class="n">scale</span> <span class="o">=</span> <span class="mf">0.001</span> <span class="c1"># l1 Regularization hyperparameter</span>
<span class="n">xentropy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sparse_softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
<span class="n">base_loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">xentropy</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;avg_xentropy&#39;</span><span class="p">)</span>
<span class="n">reg_losses</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">W1</span><span class="p">))</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">W2</span><span class="p">))</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">base_loss</span><span class="p">,</span> <span class="n">scale</span><span class="o">*</span><span class="n">reg_losses</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;loss&#39;</span><span class="p">)</span>
</pre></div>
<p>If there are many layer, there is a better option. Many functions that create vaiables (such as <code>get_variable()</code>) or <code>tf.layers.dense()</code>) accept a <code>*_regularizer</code> argument for each created variable (e.g., <code>kernel_regularizer</code>).
You can pass any function that takes weights as an argument and returns the corresponding regularization loss. The <code>l1_regularizer()</code>, <code>l2_regularizer()</code>, and <code>l1_l2_regularizaer()</code> functions return such functions.</p>
<div class="highlight"><pre><span></span><span class="n">my_dense_layer_with_l1_reg</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">dense</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span> <span class="n">kernel_regularizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">l1_regularizer</span><span class="p">(</span><span class="n">scale</span><span class="p">))</span>
</pre></div>
<p>The regularizations are represented and computed by the nodes in the graph. TensorFlow automatically creates these nodes and add them to a special collection containing all the regularization losses. You just need to add these regularization losses to your overall loss, like this:</p>
<div class="highlight"><pre><span></span><span class="n">reg_losses</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_collection</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">GraphKeys</span><span class="o">.</span><span class="n">REGULARIZATION_LOSSES</span><span class="p">)</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">add_n</span><span class="p">([</span><span class="n">base_loss</span><span class="p">]</span> <span class="o">+</span> <span class="n">reg_losses</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;loss&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="dropout-todo">
<h4>Dropout :todo</h4>
</div>
<div class="section" id="max-norm-regularization">
<h4>Max-Norm Regularization</h4>
<p>Max-Norm regularization is a very popular regularization technique for NNs.</p>
<dl class="docutils">
<dt>How does Max-Norm Regularization work</dt>
<dd>For each neuron, it constrains the weights <span class="math">\(\vec{w}\)</span> of the incoming connections such that <span class="math">\(||\vec{w}||_2 \le r\)</span>, where <span class="math">\(r\)</span> is the max-norm hyperparameter and <span class="math">\(||\cdot ||_2\)</span> is the <span class="math">\(l_2\)</span> norm.
We typically implement this constraint by computing <span class="math">\(||\vec{w}||_2\)</span> after each training step and clipping <span class="math">\(\vec{w}\)</span> if needed (<span class="math">\(\vec{w} \leftarrow \vec{w}\frac{r}{||\vec{w}||_2}\)</span>). Reducing <span class="math">\(r\)</span> increases the amount of regularizatin and helps reduce overfitting. Max-norm
regularization can also alleviate the vanishing/exploding gradient problems (if you are not using batch normalization).</dd>
</dl>
<p>todo: implement</p>
</div>
<div class="section" id="data-augmentation">
<h4>Data Augmentation</h4>
<p>Generate new training instances from existing ones, artificially boosting the size of the training set. This will reduce overfitting, making this a regularization technique. The trick is to generate <strong>realistic</strong> training instances; ideally,
a human should not be able to tell which instanceswere generated and which ones were not. More over, simply adding white noise will not help; the modifications you apply should be learnable (white noise is not)</p>
<p>e.g., shift, rotate, flip( for symmetrical objects), resize, adjust constrast or combination of transformations and then add the resulting pictures to the training set. This forces the model to be more tolerant to the position, orientation,lighting conditions, and size of the objects in the picture.</p>
<p>It is preferable to generate training instances on the fly during training rather than wasting storage space and network bandwidth.</p>
<p>TF offers several image manipulation operations. See API for details.</p>
</div>
<div class="section" id="skip-connections">
<h4>Skip connections</h4>
<p>Another powerful technique to train very deep NNs is to add <strong>skip connections</strong> (that is, when you add the input of a layer to the output of a higher layer, e.g., in deep residual networks.</p>
</div>
</div>
<div class="section" id="practical-guidelines">
<h3>Practical Guidelines</h3>
<p>This configuration will work fine in most cases - <strong>default DNN configuration</strong>:</p>
<ul class="simple">
<li>Initialization: He Initialization</li>
<li>Activation function: ELU</li>
<li>Normalization: Batch Normalization</li>
<li>Regularization: Dropout</li>
<li>Optimizer: Nesterov Accelerated Gradient</li>
<li>Learning rate schedule: None</li>
</ul>
<p>You should try to reuse parts of a pretrained NN if you can find one that solves a similar problem.</p>
<p>This default configuration may need to be tweaked:</p>
<ul class="simple">
<li>If you can't find a good learning rate (slow convergence or suboptimal accuracy), then you can try adding a learning schedule such as exponential decay.</li>
<li>If your training set is a bit too small, you can implement data augmentation.</li>
<li>If you need a sparse model, you can add some <span class="math">\(l_1\)</span> regularization to the mix (and optionally zero out the tiny weights after training). If you need an even sparser model, you can try using
FTRL instead of Adam optimization, along with <span class="math">\(l_1\)</span> regularization.</li>
<li>If you need a lightning-fast model at runtime, you may want to drop Batch Normalization, and possibly replace the ELU activation function with the leaky ReLU. Having a sparse model will also help.</li>
</ul>
<p>With these guidelines, you are now ready to train very deep nets.</p>
<table class="docutils citation" frame="void" id="tdr11" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id9">[tdr11]</a></td><td><strong>The dying Relu</strong>: during training, some neurons effectively die, meaning they stop outputting anything other than 0. In some cases, you may find that half of your network's neurons are dead, especially if you used a large learning rate.
During training, if a neuron's weights get updated such that the weighted sum of the neuron's inputs is negative, it will start outputting 0. When this happen, the neuron is unlikely to comback to life since the gradient of the ReLU function
is 0 when its input is negative.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tlr11" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id10">[tlr11]</a></td><td><strong>The leaky Relu</strong>: <span class="math">\(\mathrm{LeakyReLU}_\alpha (z) = \mathrm{max}(\alpha z, z)\)</span>. The <span class="math">\(\alpha\)</span> defines how much the function &quot;leaks&quot;, typically set to 0.01.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="trr11" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id12">[trr11]</a></td><td><strong>The randomized ReLU (RReLU)</strong>: Similar to the leaky ReLU, where <span class="math">\(\alpha\)</span> is picked randomly in a given range during training, and it is fixed to an average value during testing.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="tpr11" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id13">[tpr11]</a></td><td><strong>The parametric ReLU (PReLU)</strong>: Similar to the leaky ReLU, where <span class="math">\(\alpha\)</span> is authorized to be learned during training (a parameter that can be modified by backpropagation instead of being a hyperparameter).</td></tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="gb10" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[GB10]</td><td><em>(<a class="fn-backref" href="#id7">1</a>, <a class="fn-backref" href="#id8">2</a>)</em> Glorot, X. &amp; Bengio, Y.. (2010). Understanding the difficulty of training deep feedforward neural networks. Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, in PMLR 9:249-256</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="xwcl15" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id11">[XWCL15]</a></td><td>&quot;Empirical Evaluation of Rectified Activations in Convolution Network&quot;, B. Xu et al. (2015).</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="cuh15" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id14">[CUH15]</a></td><td>&quot;Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)&quot;, D. Clevert, T. Unterhiner, S. Hochreiter (2015).</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="is15" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id15">[IS15]</a></td><td>&quot;Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift&quot;, S. Ioffe and C. Szegedy (2015).</td></tr>
</tbody>
</table>
</div>
</div>
<hr class="docutils" />
<div class="section" id="chapter-13-convolutional-neural-networks">
<h2>Chapter 13 - Convolutional Neural Networks</h2>
<p><strong>Convolutional neural networks (CNNs)</strong> emerged from the study of the brain's visual cortex and they have been used in image recognition since the 1980s.</p>
<p>In the last few years, thanks to <em>the increase in computational power</em>, <em>the amount of available training data</em>, <em>the tricks for training deep nets</em>, CNNs have managed to chieve superhuman performance on some complex visual tasks.</p>
<p>CNN are not restricted to visual perception, other tasks such as voice regocnition and Natural Language Processing are also involved.</p>
<div class="section" id="the-architecture-of-the-visual-cortex">
<h3>The Architecture of the Visual Cortex</h3>
<p>The researches <a class="citation-reference" href="#hw58" id="id16">[HW58]</a>, <a class="citation-reference" href="#hw59" id="id17">[HW59]</a> and <a class="citation-reference" href="#hw68" id="id18">[HW68]</a> showed that many neurons in the visual cortex have a small <strong>local receptive field</strong> <a class="citation-reference" href="#lrf13" id="id19">[lrf13]</a> . The receptive fields of
different neurons may overlap, and together they tile <strong>the whole visual vield</strong>. They also showed that some neurons react only to images of horizontal lines, while others react only to
lines with different orientations (two neurons may have the same receptive field but react to different line orientations).</p>
<p>They noticed that some neurons have larger receptive fileds, and they react to more complex patterns that are combinations of the lower-level patterns. These observations led to
the idea that the higher-level neurons are based on the outputs of neighboring lower-level neurons (with each neuron is connected only to a few neurons from the previous layer). This
powerful architecture is able to detect all sorts of complex patterns in any area of the visual field.</p>
<p><a class="citation-reference" href="#fuk80" id="id20">[Fuk80]</a> gradually evolved into convolutional CNNs.</p>
<p><a class="citation-reference" href="#lbbh98" id="id21">[LBBH98]</a> is the milestone which introduced the famous LeNet-5 architecture, widely used to recognize handwritten check numbers. It introduces two new building blocks: <strong>convolutional layers</strong> and <strong>pooling layers</strong>.</p>
<p><strong>Why not simply use a regular DNN with fully connected layers for the image recognition tasks?</strong></p>
<ul class="simple">
<li>Huge number of parameters are required for large Fully Connected Layers</li>
<li>CNNs solve this problem using <strong>partially connected layers</strong> <a class="citation-reference" href="#pcl13" id="id22">[pcl13]</a></li>
</ul>
</div>
<div class="section" id="convolutional-layer">
<h3>Convolutional Layer</h3>
<p>The most important building block of a CNN is the <strong>convolutional layer (conv layer)</strong> <a class="reference external" href="https://en.wikipedia.org/wiki/Convolution">conv layers actually use cross-correlations, which are very similar to convolutions</a> : neurons in the first conv layer are not connected to every single pixel in the input image, but only to pixels in their receptive fields.
It also applies to the second, third ... layers, which allows the NN to concentrate on low-level features in the first hidden layer, then assemble them into higher-level features in the next hidden layer, and so on, which is
also the common case in real-world images.</p>
<p>Normal case: a neuron in row <span class="math">\(i\)</span> column <span class="math">\(j\)</span> of a given layer is connected to the outputs of the neurons in the previous layer, located in rows <span class="math">\(i\)</span> to <span class="math">\(i+f_h -1\)</span>, columns <span class="math">\(j\)</span> to <span class="math">\(j+f_w -1\)</span>, where
<span class="math">\(f_h, f_w\)</span> are the height and width of the receptive fields.</p>
<p><strong>zero padding</strong>: add zeros around the input in order for a layer to have the same height and width as the previous layer.</p>
<p>It is also possible to connect a large input layer to a much smaller layer by spacing out the receptive field with <strong>stride</strong>, which is the distance between two consecutive receptive fields.</p>
<p>Conv layer with stride: a neuron located in row <span class="math">\(i\)</span>, column <span class="math">\(j\)</span> in the upper layer is connected to the outputs of the neurons in the previous layer located in rows <span class="math">\(i \times s_h\)</span> to <span class="math">\(i \times s_h + f_h -1\)</span>,
columns <span class="math">\(j \times s_w + f_w -1\)</span>, where <span class="math">\(s_h, s_w\)</span> are the vertical and horizontal strides.</p>
<div class="section" id="filters">
<h4>Filters</h4>
<p>A neuron's weights can be represented as a small image the size of the receptive field. The weights are called <strong>filters</strong> or <strong>convolution kernels</strong>.</p>
<p>All neurons in a layer use the same filter, gives you a <strong>feature map</strong>, which highlights the area in an image that are most similar to the filter.</p>
<p>During training, a CNN finds the most useful filters for its task, and it learns to combine them into more complex patterns.</p>
</div>
<div class="section" id="stacking-multiple-feature-maps">
<h4>Stacking Multiple Feature Maps</h4>
<p>In reality, we use conv layers composed of several feature maps of equal sizes instead of one single thin 2D layer, so it (the conv layer) is more accurately represented in 3D.</p>
<p>Within one feature map, all neurons share the same parameters: weights (i.e., the <em>kernel</em>, one per feature map), and the <em>bias term</em> (one per feature map), but different feature maps may have different
parameters. A neuron's receptived field is the same as described earlier, but it extends across all the previous layer's feature maps. In short, a conv layer simultaneously applies multiple filters
to its inputs, making it capable of detecting multiple feature anywhere in its inputs.</p>
<p><em>The face that all neurons in a feature map share the same parameters dramatically reduces the number of parameters in the model, but most importantly it means that once the CNN has learned to recognize a pattern in one location,
it can recognize it in any other location. In contrast, once a regular DNN has learned to recognize a pattern in one location, it can recognize it only in that particular location.</em></p>
<p>Input images are probably composed of multiple <strong>sublayers</strong>: one per <strong>color channels</strong>.</p>
<p>TODO: equation 13-1</p>
</div>
<div class="section" id="tensorflow-implementation">
<h4>TensorFlow Implementation</h4>
<p>In TF, the typical representations are</p>
<ul class="simple">
<li>for an image: 3D tensor of shape <span class="math">\([height, width, channels]\)</span></li>
<li>for a mini-batch: 4D tensor of shape <span class="math">\([\text{mini-batch size}, height, width, channels]\)</span></li>
<li>for the weights of a conv layer: 4D tensor of shape <span class="math">\([f_h, f_w, f_n, f_{n'}]\)</span>, where <span class="math">\(f_n, f_{n'}\)</span> are the number of feature maps (kernels)
of this layer and the previous layer</li>
<li>for the bias term of a conv layer: 1D tensor of shape <span class="math">\([f_n]\)</span></li>
</ul>
<p>An example:</p>
<ol class="arabic simple">
<li>loads two sample images <tt class="docutils literal">sklearn.datasets.load_sample_images</tt></li>
<li>creates two 7x7 filters</li>
<li>apply them to both images using a conv layer using <tt class="docutils literal">tf.nn.conv2d()</tt> with zero padding and a stride of 2</li>
<li>plots one of the resulting feature maps</li>
</ol>
<p><tt class="docutils literal">tf.nn.conv2d()</tt>:</p>
<ol class="arabic">
<li><p class="first"><tt class="docutils literal">X</tt>: mini-batch input 4D tensor</p>
</li>
<li><p class="first"><tt class="docutils literal">filters</tt>: the set of filters (4D tensor)</p>
</li>
<li><p class="first"><tt class="docutils literal">strides</tt>: 4 element 1D array. The control elements are the vertical and horizontal strides (<span class="math">\(s_h, s_w\)</span>). The first and last elements must currently be equal to 1.
They may one day be used to specify a batch stride (to skip some instances) and a channel stride (to skip some of the previous layer's feature maps or channels).</p>
</li>
<li><p class="first"><tt class="docutils literal">padding</tt> must be either &quot;VALID&quot; or &quot;SAME&quot;:</p>
<ul>
<li><p class="first">&quot;VALID&quot;: the conv layer does not use zero padding, and may ignore some rows and columns at bottom and right of the input image depending on the stride</p>
</li>
<li><p class="first">&quot;SAME&quot;: conv layer uses zero padding if necessary. <strong>The number of output neurons is equal to the number of input neurons divided by the stride, rounded up.</strong>
Then zeros are added as evenly as possible around the inputs.</p>
</li>
<li><p class="first"><strong>How to calculate the size of the feature map?</strong> <a class="reference external" href="https://www.tensorflow.org/api_guides/python/nn#Convolution">TensorFlow implementation</a></p>
<ul>
<li><p class="first">&quot;VALID&quot;:</p>
<div class="math">
\begin{equation*}
output\_width = \Bigl\lceil \frac{input\_width - filter\_width + 1}{stride} \Bigr\rceil\qquad
output\_height = \Bigl\lceil \frac{input\_height - filter\_height + 1}{stride}  \Bigr\rceil\qquad
\end{equation*}
</div>
</li>
<li><p class="first">&quot;SAME&quot;: <a class="reference external" href="https://www.tensorflow.org/api_guides/python/nn#Notes_on_SAME_Convolution_Padding">TensorFlow: Notes on SAME Convolutional Padding</a></p>
<div class="math">
\begin{equation*}
output\_width = \Bigl\lceil \frac{input\_width}{stride} \Bigr\rceil\qquad
output\_height = \Bigl\lceil \frac{input\_height}{stride} \Bigr\rceil\qquad
\end{equation*}
</div>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>In a real CNN you would let the training algorithm discover the best filters automatically. You can use <tt class="docutils literal">tf.layers.conv2d()</tt> to create the filters variable (<strong>kernel</strong>) for you, and
initialize it randomly: <tt class="docutils literal">conv = tf.layers.conv2d(X, filters = 2, kernel_size = 7, strides = [2, 2], padding = &quot;SAME&quot;)</tt>: 2 kernels, 7x7 kernel size, horizontal stride = 2, vertical stride = 2.</p>
<p>The conv layers have quite a few hyperparameters. As always you can use corss-validation to find the right hyperparameter values, but this is very time-consuming.
We'll discuss common CNN architectures later, to give you some idea of what hyperparameter values work best in practice.</p>
</div>
<div class="section" id="memory-requirements">
<h4>Memory Requirements</h4>
<p>The training of CNN require a huge amount of RAM because the reverse pass of backpropagation requires all the intermediate values computed during the forward pass. The amount of RAM
neede is at least the total amount of RAM required by all layers.</p>
<p><strong>The estimation of memory consumption</strong> in the book.</p>
<p>During <strong>inference</strong> <a class="citation-reference" href="#inf13" id="id24">[inf13]</a> the RAM occupied by one layer can be released as soon as the next layer has been computed, so you only need as much RAM as required by two consecutive layers.</p>
<p>If training crashes because of an out-of-memory error, you can try reducing the mini-batch size or reducing dimensionality using a stride, or removing a few layers, or try using 16-bit
floats instead of 32-bit floats, or distribute the CNN across multiple devices.</p>
</div>
</div>
<div class="section" id="pooling-layer">
<h3>Pooling Layer</h3>
<p>The goal of this layer is to <strong>subsample</strong> (i.e., shrink) the input image in order to reduce the computational load, the memory usage, and the number of parameters (thereby limiting
the risk of overfitting). Reducing the input image size also makes the NN tolerate a little bit of image shift (<strong>location invariance</strong>).</p>
<p><strong>Just like in conv layers, each neuron in a pooling layer has a rectangular receptive field.</strong> You need to define its size, the stride, and the padding type. <strong>But a pooling neuron has
no weights</strong>: all it does is aggregate the inputs using an aggregation function such as the max or mean.</p>
<dl class="docutils">
<dt><strong>max pooling layer</strong></dt>
<dd>Most common type of pooling layer. Only the max input value in each kernel makes it to the next layer, the other inputs are dropped.</dd>
<dt><strong>Pooling kernel</strong></dt>
<dd>similar to a convolutional kernel but has no weights or bias.</dd>
</dl>
<p><strong>A pooling layer typically works on every input channel independently, so the output depth is the same as the input depth.</strong> You may alternatively pool over the depth dimension, as
we will see next, in which case the image's spatial dimensions (height and width) remain unchanged, but the number of channels is reduced.
<tt class="docutils literal">tf.nn.max_pool(X, <span class="pre">ksize=[1,2,2,1],</span> <span class="pre">strides=[1,2,2,1],</span> <span class="pre">padding=&quot;VALID&quot;)</span></tt></p>
<ul class="simple">
<li>The <tt class="docutils literal">ksize</tt> argument contains the kernel shape along all four dimensions of the input tensor <tt class="docutils literal">[batch_size, height, width, channels]</tt>. TF currently does not support pooling over
multiple instances, so <tt class="docutils literal">ksize[0]</tt> must be equal to 1. Moreover, it does not support pooling over both the <strong>spatial dimensions (height and width)</strong> and the <strong>depth information</strong>, so
either <tt class="docutils literal">ksize[1]</tt> and <tt class="docutils literal">ksize[2]</tt> must both be equal to 1, or <tt class="docutils literal">ksize[3]</tt> must be equal to 1.</li>
<li>You can also create an <strong>average pooling layer</strong> <tt class="docutils literal">tf.nn.avg_pool()</tt> instead of <tt class="docutils literal">tf.nn.max_pool()</tt></li>
</ul>
</div>
<div class="section" id="cnn-architectures">
<h3>CNN Architectures</h3>
<p>Typical CNN architectures stack a few con layers (each one generally followed by a ReLU layer), then a pooling layer, then another few conv layers (+ReLU), then another pooling layer, and so on. The image gets smaller
and smaller as it progresses through the network, but it also typically gets <strong>deeper and deeper</strong> (i.e., with more feature maps) thanks to the conv layers. At the top of the stack, a regular feedforward NN is added,
composed of a few fully connected layers (+ReLUs), and the final layer outputs the prediction (e.g., a softmax layer that outputs estimated class probabilities).</p>
<p>You can get the effect of a 9x9 kernel by stacking two 3x3 kernels on top of each other, for a lot less computation and parameters.</p>
<p>A good measure of the progress of variants of the fundamental architecture above, is the error rate in competitions such as the <strong>ILSVRC ImageNet challenge</strong>. <strong>Top-5 error rate for image classification</strong> <a class="citation-reference" href="#trf13" id="id25">[trf13]</a>.
Looking at the evolution of the winning entries is a good way to understand how CNN work.</p>
<ul class="simple">
<li>LeNet-5 1998 (classic for handwritten digits recognition)</li>
<li>AlexNet 2012, ImageNet top-5 error rate: 17%.</li>
<li>GoogLeNet 2014, ImageNet top-5 error rate: 7%.</li>
<li>ResNet 2015, ImageNet top-5 error rate: 3.6%.</li>
</ul>
<div class="section" id="other-visual-tasks">
<h4>Other Visual Tasks</h4>
<ul class="simple">
<li><strong>Object Detection and Localization</strong>:<ul>
<li>The NN typically outputs a sequence of bounding boxes around various objects in the image.</li>
<li><a class="reference external" href="goo.gl/ZKuDtr">goo.gl/ZKuDtr</a> outputs a heat map for each object class</li>
<li><a class="reference external" href="goo.gl/upuHl2">goo.gl/upuHl2</a> uses a combination of a CNN to detect faces and a RNN to output a sequence of bounding boxes around them.</li>
</ul>
</li>
<li><strong>Image Segmentation</strong>:<ul>
<li>The net outputs an image (usually of the same size as the input) where each pixel indicates the class of the object to which the corresponding input pixel belongs.</li>
<li>For example, check out this paper <a class="reference external" href="goo.gl/7ReZql">goo.gl/7ReZql</a></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="lenet-5">
<h4>LeNet-5</h4>
<p>Created by Yann LeCun in 1998 and widely used for handwritten digits.</p>
<p>TODO: architecture</p>
<p>Note:</p>
<ol class="arabic simple">
<li>MNIST images are 28x28 pixels, they are zero-padded to 32x32 pixels and normalized before being fed to the network. The rest of the network does not use any padding, thus the size keeps shrinking as the image progresses through the network.</li>
<li>The <tt class="docutils literal">avg_pooling</tt> layers are slightly more complex than usual: each neuron computes the mean of its input, then multiplies the result by a learnable coefficient (one per map) and adds a learnable bias term (one per map), then finally
applies the activation function</li>
<li>Most neurons in C3 maps are connected to neurons in only 3 or 4 S2 maps (instead of all six S2 maps)</li>
<li>The output layer is a bit special: each neuron outputs the square of the Euclidean distance between its input vector and its weight vector. <em>Each output measures how much the image belongs to a particular digit class.</em> The cross entropy cost
function is now preferred, as it penalizes bad predictions much more, producing larger gradients and thus converging faster.</li>
</ol>
</div>
<div class="section" id="alexnet-ksh12">
<h4>AlexNet  <a class="citation-reference" href="#ksh12" id="id26">[KSH12]</a></h4>
<p>Similar to LeNet-5 but much larger and deeper. It's the first to stack convlayers directly on top of each other, instead of stacking a pooling layer on top of each conv layer.</p>
<p>TODO: architecture</p>
<p>To reduce overfitting:</p>
<ol class="arabic simple">
<li>They applied dropout (with a 50% dropout rate) during training to the outputs of layers F8 and F9.</li>
<li>They performed data augmentation by randomly shifting the training images by various offsets, flipping them horizontally, and changing the lighting conditions</li>
</ol>
<p>AlexNet also uses a competitive normalization step immediately after the ReLU step of layers C1 and C3, called <strong>local response normalization</strong> <a class="citation-reference" href="#lrn13" id="id27">[lrn13]</a>. This step can
be implemented using TF's <tt class="docutils literal">tf.nn.local_response_normalization()</tt> operation.</p>
</div>
<div class="section" id="todo-googlenet">
<h4>TODO: GoogLeNet</h4>
</div>
<div class="section" id="resnet">
<h4>ResNet</h4>
<p>Residual Network, winner of the ILSVRC 2015 challenge with 3.6% top-5 error rate. It's an extremely deep CNN composed of 152 layers.
The key to being able to train such a deep network is to use <strong>skip connections</strong> or also called <strong>shortcut connections</strong>: the signal feeding into a layer is also added to the output of a layer located a bit higher up
the stack.</p>
<dl class="docutils">
<dt><strong>Residual Learning</strong></dt>
<dd>When training a NN, the goal is to make it model a target function <span class="math">\(h(\vec{x})\)</span>. If you add the input <span class="math">\(\vec{x}\)</span> to the output of the network (i.e., <strong>you add a skip connection</strong>), then the network will be
forced to model <span class="math">\(f(\vec{x}) = h(\vec{x}) - \vec{x}\)</span> rather than <span class="math">\(h(\vec{x})\)</span>. This is called residual learning.</dd>
</dl>
<p>When you initialize a regular NN, its weights are close to zero, so the network just outputs values close to zero. If you add a skip connection, the resulting network just outputs a copy of its inputs; in other words, it initially models the identity function. If
the target function is fairly close to the identity function (which is often the case), this will speed up training considerably. Moreover, if you add many skip connections, the network can start making progress even if several layers have not started learning yet
(the normal network layers, instead, initially outputs close to zero and block backpropagation) Thanks to skip connections, the signal can easily make its way across the whole network. The Deep ResNet can be seen as a stack of <strong>Residual Units</strong> <a class="citation-reference" href="#ru13" id="id28">[ru13]</a> .</p>
<p>TODO: architecture</p>
<p>The architecture starts and ends exactly like GoogLeNet (except without a dropout layer) and in between is just a very deep stack of simple residual units. Note that the number of feature maps is doubled every few residual units, at the same time as their height and width are halved
(using a convolutional layer with stride 2). <em>When this happends the input cannot be added directly to the outputs of the residual unit since they don't have the same shape</em>. To solve this problem, the inputs are passed through a 1x1 convolutional layer with stride 2 and the right
number of output feature maps.</p>
<p><a class="reference external" href="https://www.kaggle.com/pytorch/resnet34">ResNet-34</a> is the RestNet with 34 layers (only counting the conv layers and the fully connected layer) containing 3 residual units that output 64 feature maps, 4 RUs with 128 maps, 6 RUs with 256 maps, and 3 RUs with 512 maps.
More deeper RestNets, such as RestNet-152, use slightly different residual units. Instead of two 3x3 conv layers, they use three conv layers. TODO: details.</p>
<p>One clear trend is that CNNs keep getting deeper and deeper. They are also getting lighter, requiring fewer and fewer parameters. At present, the ResNet architecture is both the most powerful and arguabley the simplest, so it is really the one you should probably use for now,
but keep looking at the ILSVRC challenge every year. The winner of 2016 achieved a 2.99% error rate by training combinations of the previous models and joined them into an ensemble.</p>
<p>There are a few other architectures, in particular <strong>VGGNet</strong> (runner-up of the ILSVRC 2014 challenge) and <strong>Inception-v4</strong> (which merges the ideas of GoogLeNet and ResNet and achieves close to 3% top-5 error rate on ImageNet classification).</p>
</div>
<div class="section" id="tensorflow-convolution-operations">
<h4>TensorFlow Convolution Operations</h4>
<p>TensorFlow also offers a few other kinds of convolutional layers:</p>
<ul class="simple">
<li><tt class="docutils literal">tf.layers.conv1d()</tt>, convolutional layer for 1D inputs. Useful, for example, in NLP, where a sentence may be represented as a 1D array of words, and the receptive field covers a few neighboring words.</li>
<li><tt class="docutils literal">tf.layers.conv3d()</tt>, creates a von layer for 3D inputs, such as <a class="reference external" href="https://de.wikipedia.org/wiki/Positronen-Emissions-Tomographie">3D PET scan</a></li>
<li><tt class="docutils literal">tf.nn.atrous_conv2d()</tt>, creates an <strong>atrous convolutional layer</strong> (&quot;à trous&quot; is French for &quot;with holes&quot;). This is equivalent to using a regular conv layer with a filter dilated by inserting rows and columns of zeros (i.e., holes). This allows the convolutional layer
to have a larger receptive field at no computational price and using no extra parameters. An example here <a class="citation-reference" href="#acl13" id="id29">[acl13]</a>.</li>
<li><tt class="docutils literal">tf.layers.conv2d_transpose()</tt> creates a <strong>transpose convolutional layer</strong>, sometimes called a <strong>deconvolutional layer</strong> <a class="citation-reference" href="#dl13" id="id30">[dl13]</a> which <strong>upsamples an image</strong>. It does so by inserting zeros between the inputs, you can think of this as a regular convolutional layer
using a fractional stride. Upsampling is useful, for example, in image segmentation: in a typical CNN, feature maps get smaller and smaller as you progress through the network, so if you want to output an image of the same size as the input, you need and upsampling layer.</li>
<li><tt class="docutils literal">tf.nn.depthwise_conv2d()</tt> creates a <strong>depthwise convolutional layer</strong> that applies every filter to every individual input channel independently. Thus, if there are <span class="math">\(f_n\)</span> filters and <span class="math">\(f_{n'}\)</span> input channels, then this will
output <span class="math">\(f_n \times f_{n'}\)</span> feature maps. <strong>distinguish with the normal ``tf.layers.conv2d()``</strong>.</li>
<li><tt class="docutils literal">tf.layers.separable_conv2d()</tt> creates a <strong>separable convolutional layer</strong> that first acts like a depthwise conv layer, then applies a 1x1 conv layer to the resulting feature maps. This makes it possible to apply filters to arbitrary sets of inputs channels.</li>
</ul>
<table class="docutils citation" frame="void" id="lrf13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id19">[lrf13]</a></td><td>Many neurons in the visual cortex react only to visual stimuli located in a limited region of the visual field.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="pcl13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id22">[pcl13]</a></td><td><strong>Partially connected layers</strong>: compared to regular fully connected neural networks, a neuron in the convolutional layer is conneted to the neurons, which are
located in its receptive field in the previous level.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="inf13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id24">[inf13]</a></td><td><strong>Inference</strong>: The process which makes prediction for a new instance.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="trf13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id25">[trf13]</a></td><td><strong>Top-5 error rate for image classification</strong>: The number of test images for which the system's top 5 predictions did not include the correct answer.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="lrn13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id27">[lrn13]</a></td><td><dl class="first docutils">
<dt><strong>Local Response Normalization (LRN)</strong>: This form of normalization makes the neurons that most strongly activate inhibit neurons</dt>
<dd><p class="first">at the same location but in neighboring feature maps (such competitive activation has been observed in biological neurons). This encourages different feature maps to specialize, pushing them apart and forcing them to explore a wider range of features,
ultimately improving generalization.</p>
<div class="last math">
\begin{equation*}
b_i = a_i \left( k+ \alpha \sum_{\mathrm{max}(0, i - \frac{r}{2})}^{\mathrm{min}(i+\frac{r}{2}, f_n -1)} a_j^2 \right) ^{-\beta}
\end{equation*}
</div>
</dd>
</dl>
<ul class="last simple">
<li><span class="math">\(a_i\)</span> is the activation of that neuron after the ReLU step, but before the normalization</li>
<li><span class="math">\(f_n\)</span> is the number of feature maps</li>
<li><span class="math">\(k, \alpha, \beta, r\)</span> are hyper parameters. <span class="math">\(k\)</span> is called the bias, and <span class="math">\(r\)</span> is called the <em>depth radius</em>.</li>
<li><span class="math">\(b_i\)</span> is the normalized output of the neuron located in feature map <span class="math">\(i\)</span>, at some row <span class="math">\(u\)</span> and column <span class="math">\(v\)</span> (note that in this equation we consider only neurons located at this row and column, so <span class="math">\(u, v\)</span> are not shown).</li>
</ul>
</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ru13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id28">[ru13]</a></td><td><strong>Residual Units</strong>: A small neural network with a skip connection. The real residual unit in ResNet-34 is composed of two convolutional layers, with Batch Normalization (BN) and ReLU activation, using
3x3 kernels and preserving spatial dimensions (stride 1, SAME padding).</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="acl13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id29">[acl13]</a></td><td>A 1x3 filter <tt class="docutils literal">[[1, 2, 3]]</tt> may be dilated with a <strong>dilation rate</strong> of 4, resulting in a <strong>dilated filter</strong> <tt class="docutils literal">[[1, 0, 0, 0, 2, 0, 0, 0, 3]]</tt>.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="dl13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id30">[dl13]</a></td><td>This layer does <strong>not</strong> perform a deconvolution, which is a well-defined mathematical operation (the inverse of a convolution).</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="hw58" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id16">[HW58]</a></td><td>&quot;Single Unit Activity in Striate Cortex of Unrestrained Cats,&quot; D. Hubel and T. Wiesel (1958).</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="hw59" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id17">[HW59]</a></td><td>&quot;Receptive Fields of Single Neurones in the Cat's Striate Cortex,&quot; D. Hubel and T. Wiesel (1959).</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="hw68" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id18">[HW68]</a></td><td>&quot;Receptive Fields and Functional Architecture of Monkey Striate Cortex,&quot; D. Hubel and T. Wiesel (1968).</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="fuk80" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id20">[Fuk80]</a></td><td>&quot;Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position,&quot; K. Fukushima (1980).</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="lbbh98" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id21">[LBBH98]</a></td><td>&quot;Gradient-Based Learning Applied to Document Recognition&quot;, LeCun, Y. et al.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="ksh12" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id26">[KSH12]</a></td><td>&quot;ImageNet Classification with Deep Convolutional Neural Networks&quot;, A. Krizhevsky et al. (2012).</td></tr>
</tbody>
</table>
</div>
</div>
</div>
<hr class="docutils" />
<div class="section" id="chapter-15-autoencoders">
<h2>Chapter 15 - Autoencoders</h2>
<p>Autoencoders are ANNs capable of learning the <strong>codings</strong> <a class="citation-reference" href="#cod12" id="id31">[cod12]</a> , without any supervision.</p>
<ul class="simple">
<li>These codings typically have a much lower dimensionality than the input data, making autoencoders useful for <strong>dimensionality reduction</strong>.</li>
<li>Moreover, autoencoders acts as powerful <strong>feature detectors</strong> and they can be used for <strong>unsupervised pretraining of DNNs</strong>.</li>
<li>Lastly, they are capable of randomly generating new data that look very similar to the training data; this is called a <strong>generative model</strong>.</li>
</ul>
<p>Autoencoders works by simply learning to copy their inputs to their outputs. By constraining the network in various ways, we can make this task rather difficult thus making this task non-trivial.
The constraints forces the autoencoders to learn efficient ways of representing the data. The codings are byproducts of the autoencoder's attempt to learn the identity function under some constraints.
Some possible constraint methods are:</p>
<ul class="simple">
<li>limit the size of the internal representations</li>
<li>add noise to the inputs and train the network to recover the original inputs.</li>
</ul>
<div class="section" id="efficient-data-representations">
<h3>Efficient Data Representations</h3>
<p>It is the fact that it is hard to memorize long sequences that makes it useful to recognize patterns, and hopefully this clarifies why contraining an autoencoder during training pushes it to discover and exploit patterns in the data.</p>
<p><a class="citation-reference" href="#cs73" id="id32">[CS73]</a> studied the famous relationship between memory perception, and pattern matching. The chess players were able to memorize the positions of all the pieces in a <em>realistic game*</em> by looking at the board for just 5 seconds. While it is not
even possible for normal people. But If the placement of the pieces are totally random, the chess experts are not better than you and i. They just see chess patterns more easily thanks to their experience with the game.
<strong>Noticing patterns helps them store information efficiently.</strong></p>
<p>Just like a chess player, an autoencoder looks at the inputs, converts them to an efficient internal representation, and then spits out something that (hopefully) looks very close to the inputs.</p>
<p>An autoencoder is always composed of two parts: an <strong>encoder</strong> - <strong>recognition network</strong> - that converts the inputs to an internal representation, followed by a <strong>decoder</strong> - <strong>generative network</strong> - that converts the internal representation to the outputs.</p>
<dl class="docutils">
<dt>Architecture of an autoencoder</dt>
<dd>An autoencoder typically has the same architecture as a MLP, except that the number of neurons in the output layer must be equal to the number of inputs. The outputs are often called <strong>the reconstructions</strong> since the autoencoder tries to reconstruct the inputs, and the cost function contains a
<strong>reconstruction loss</strong> that penalizes the model when the reconstructions are different from the inputs.</dd>
<dt>Autoencoder is undercomplete</dt>
<dd>Because the internal representation has a lower dimensionality than the input data, the autoencoder is said to be <strong>undercomplete</strong>.
An undercomplete autoencoder cannot trivially copy its inputs to the codings, yet it must find a way to output a copy of its inputs. It is forced to learn the most important features in the input data (and drop the unimportant ones).</dd>
</dl>
</div>
<div class="section" id="performing-pca-with-an-undercomplete-linear-autoencoder">
<h3>Performing PCA with an Undercomplete Linear Autoencoder</h3>
<p>If the autoencoder uses only linear activations and the cost function is the MSE, then it can be shown that it ends up performing PCA.</p>
<p>Implementation Note</p>
<ol class="arabic simple">
<li>The number of outputs is equal to the number of inputs.</li>
<li>To perform simple PCA, do not use any activation functions, (i.e., all neurons are linear) and the cost function is the MSE.</li>
<li>Unsupervised (no labels!)</li>
<li>The autoencoder finds the best subspace to project the data onto, preserving as much variance in the data as it could.</li>
</ol>
</div>
<div class="section" id="stacked-autoencoders">
<h3>Stacked Autoencoders</h3>
<dl class="docutils">
<dt>Stacked Autoencoders (or Deep Autoencoders)</dt>
<dd>Autoencoders can have multiple hidden layers, just like other NNs. In this case they are called <strong>stacked autoencoders</strong> (or <strong>deep autoencoders</strong>). Adding more layers helps the autoencoder learn more complex codings.</dd>
</dl>
<p>However, one must be careful not to make the autoencoder too powerful (in this case it will map each input to a unique coding and decoder reconstruct the traning data perfectly, but it won't learn any useful data representation in the process and is unlikely to generalize well to new instances).</p>
<p>The architecture of a stacked autoencoder is typically symmetrical w.r.t. the <strong>central hidden layer</strong> (<strong>the coding layer</strong>).</p>
<table class="docutils citation" frame="void" id="cod12" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id31">[cod12]</a></td><td><strong>Coding of the data</strong>: An efficient representation of the input data. Typically have a much lower dimensionality than the input data itself.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="cs73" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id32">[CS73]</a></td><td>&quot;Perception in chess&quot;, W. Chase and H. Simon (1973)...</td></tr>
</tbody>
</table>
</div>
</div>
<script type='text/javascript'>if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width < 768) ? "left" : align;
        indent = (screen.width < 768) ? "0em" : indent;
        linebreak = (screen.width < 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
  </div>
  
<div class="article-tag-list">
<span class="label label-default">Tags</span>
	<a href="/tag/machine-learning.html"><i class="fa fa-tag"></i>Machine Learning</a>&nbsp;
	<a href="/tag/deep-learning.html"><i class="fa fa-tag"></i>Deep Learning</a>&nbsp;
	<a href="/tag/tensorflow.html"><i class="fa fa-tag"></i>TensorFlow</a>&nbsp;
	<a href="/tag/scikit-learn.html"><i class="fa fa-tag"></i>Scikit-Learn</a>&nbsp;
</div>  <hr />
  <div class="well well-sm">  <!-- Social media sharing buttons -->

    <!-- Google+ -->
    <div class="g-plus" data-action="share" data-annotation="bubble"></div>
    &nbsp;&nbsp;&nbsp;&nbsp;
    <div class="g-plusone" data-size="medium"></div>&nbsp;

    <!-- Facebook -->
    <div class="fb-like" 
        data-href="/reading-notes-hands-on-machine-learning-with-scikit-learn-and-tensorflow.html" 
        data-layout="button_count" 
        data-action="like" data-show-faces="true" 
        data-share="true">
    </div>
    &nbsp;
  </div> <!-- /Social media sharing buttons -->
</article>
        </div><!-- /content -->

        <div class="col-md-3 sidebar-nav" id="sidebar">

<div class="row">

<div class="col-xs-6 col-md-12">
<h4><i class="fa fa-comment fa-fw fa-lg"></i> Social</h4>
<ul class="list-unstyled social-links">
    <li><a href="https://www.flickr.com/people/150485183@N02/" target="_blank">
	  <i class="fa fa-flickr fa-fw fa-lg" title="Flickr"></i>
		Flickr
	</a></li>
    <li><a href="pages/images/wechat-QRcode.JPG" target="_blank">
	  <i class="fa fa-weixin fa-fw fa-lg" title="WeChat"></i>
		WeChat
	</a></li>
</ul>
</div>

<div class="col-xs-6 col-md-12">
<h4><i class="fa fa-folder fa-fw fa-lg"></i> Categories</h4>
<ul class="list-unstyled category-links">
  <li><a href="/category/reading-notes.html" >
    <i class="fa fa-folder-open fa-fw fa-lg"></i> Reading Notes</a></li>
  <li><a href="/category/vorlesung.html" >
    <i class="fa fa-folder-open fa-fw fa-lg"></i> Vorlesung</a></li>
</ul>
</div>

</div> <!-- /row -->

  <h4><i class="fa fa-link fa-fw fa-lg"></i> Links</h4>
  <ul class="list-unstyled category-links">
    <li><a href="http://getpelican.com/" >
      <i class="fa fa-fw fa-external-link-square fa-lg"></i> Pelican</a></li>
  </ul>
<h4><i class="fa fa-tags fa-fw fa-lg"></i> Tags</h4>
<p class="tag-cloud">
    <span class="tag-4">
      <a href="/tag/keras.html">
          <i class="fa fa-tag"></i>
        Keras
      </a>
    </span>
    <span class="tag-1">
      <a href="/tag/deep-learning.html">
          <i class="fa fa-tag"></i>
        Deep Learning
      </a>
    </span>
    <span class="tag-4">
      <a href="/tag/scikit-learn.html">
          <i class="fa fa-tag"></i>
        Scikit-Learn
      </a>
    </span>
    <span class="tag-4">
      <a href="/tag/machine-learning.html">
          <i class="fa fa-tag"></i>
        Machine Learning
      </a>
    </span>
    <span class="tag-4">
      <a href="/tag/tensorflow.html">
          <i class="fa fa-tag"></i>
        TensorFlow
      </a>
    </span>
    <span class="tag-1">
      <a href="/tag/shell-script.html">
          <i class="fa fa-tag"></i>
        Shell Script
      </a>
    </span>
    <span class="tag-4">
      <a href="/tag/mikroprozessor.html">
          <i class="fa fa-tag"></i>
        Mikroprozessor
      </a>
    </span>
</p>

<hr />

        </div><!--/sidebar -->
      </div><!--/row-->
    </div><!--/.container /#main-container -->

    <footer id="site-footer">
 
      <address id="site-colophon">
        <p class="text-center text-muted">
        Site built using <a href="http://getpelican.com/" target="_blank">Pelican</a>
        &nbsp;&bull;&nbsp; Theme based on
        <a href="http://www.voidynullness.net/page/voidy-bootstrap-pelican-theme/"
           target="_blank">VoidyBootstrap</a> by 
        <a href="http://www.robertiwancz.com/"
           target="_blank">RKI</a>  
        </p>
      </address><!-- /colophon  -->
    </footer>


    <!-- javascript -->
   
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js" integrity="sha384-nvAa0+6Qg9clwYCGGPpDQLVpLNn0fRaROjHqs13t4Ggj3Ez50XnGQqc/r8MhnRDZ" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"
            integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa"
            crossorigin="anonymous"></script>


<!-- Facebook -->
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));
</script>

<!-- Twitter -->
<script>!function(d,s,id){var js,fjs=d.getElementsByTagName(s)[0],p=/^http:/.test(d.location)?'http':'https';if(!d.getElementById(id)){js=d.createElement(s);js.id=id;js.src=p+'://platform.twitter.com/widgets.js';fjs.parentNode.insertBefore(js,fjs);}}(document, 'script', 'twitter-wjs');</script>

<!-- Google+ -->
<!-- Synchronous 
<script type="text/javascript" src="https://apis.google.com/js/plusone.js"></script>
-->
<!-- Asynchronous -->
<script type="text/javascript">
  (function() {
    var po = document.createElement('script'); po.type = 'text/javascript'; po.async = true;
    po.src = 'https://apis.google.com/js/platform.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(po, s);
  })();
</script>  </body>
</html>